# Quaero Configuration
# ====================
#
# This file contains ONLY user-facing configuration settings.
# Technical parameters (cache sizes, timeouts, dimensions, etc.) have sensible
# defaults hardcoded in the application and should not be modified unless you
# are debugging or have specific requirements.
#
# Configuration Load Order (priority from lowest to highest):
#   1. Defaults (hardcoded in application)
#   2. TOML file (this file)
#   3. Environment variables (QUAERO_*)
#   4. Command line flags (--port, --host, --config)
#
# Only uncomment settings you want to override from defaults.

# =============================================================================
# Environment Configuration
# =============================================================================
# Controls environment mode: "development" or "production"
# Production mode rejects test URLs (localhost, 127.0.0.1, etc.) for safety
# Default: development (allows test URLs)
# Env vars: QUAERO_ENV, GO_ENV (highest priority)

environment = "development"  # "development" or "production"

# =============================================================================
# Server Configuration
# =============================================================================
# Defaults: port=8080, host="localhost", llama_dir="./llama"
# CLI flags: --port, --host (highest priority)
# Env vars: QUAERO_SERVER_PORT, QUAERO_SERVER_HOST, QUAERO_SERVER_LLAMA_DIR

[server]
# port = 8080         # Default: 8080
# host = "localhost"  # Default: localhost
# llama_dir = "./llama"  # Directory containing llama-server binary

# =============================================================================
# Data Sources Configuration
# =============================================================================
# Configure which sources to scrape and what projects/spaces to include.
# These are user-specific and should be uncommented and customized.

[sources.confluence]
enabled = true
spaces = ["TEAM", "DOCS"]  # Customize: Your Confluence spaces

[sources.jira]
enabled = true
projects = ["DATA", "ENG"]  # Customize: Your Jira projects

[sources.github]
enabled = true
token = "${GITHUB_TOKEN}"  # Use environment variable for security
repos = ["your-org/repo1"] # Customize: Your GitHub repositories

# =============================================================================
# Storage Configuration
# =============================================================================
# Defaults: path="./data/quaero.db"
# Env vars: QUAERO_SQLITE_PATH

[storage.sqlite]
# path = "./data/quaero.db"  # Default: ./data/quaero.db

[storage.filesystem]
# images = "./data/images"           # Default: ./data/images
# attachments = "./data/attachments" # Default: ./data/attachments

# =============================================================================
# LLM Configuration
# =============================================================================
# ‚ö†Ô∏è  CRITICAL: Offline LLM requires llama-server binary + model files
# If llama-server binary is not found, service will automatically fall back
# to MOCK mode and emit detailed warnings about missing offline LLM setup.
#
# REQUIREMENTS for offline mode:
# 1. llama-server binary (see installation instructions below)
# 2. GGUF model files (embedding + chat models)
#
# üìñ See README.md 'LLM Setup' section for complete installation guide
#
# Modes:
# - "offline" (default): Local models via llama-server (100% local, no network)
# - "cloud": External API providers (sends data externally - security implications)
# - "mock": Fake responses for testing (used when offline setup incomplete)
#
# Env var: QUAERO_LLM_MODE

[llm]
mode = "offline"  # "offline" or "cloud"

# Offline Mode - Local models via llama-server (100% local, no network calls)
#
# üîß llama-server binary search paths (checked in order):
#   1. {server.llama_dir}/llama-server (default: ./llama/llama-server)
#   2. ./bin/llama-server
#   3. ./llama-server
#   4. System PATH (llama-server command)
#
# üí° Override search paths:
#   - Config: server.llama_dir = "/custom/path"
#   - Env: QUAERO_SERVER_LLAMA_DIR="/custom/path"
#
# üì¶ llama-server installation methods:
#   - Windows (winget): winget install llama.cpp
#   - macOS (Homebrew): brew install llama.cpp
#   - Linux (Nix): nix profile install nixpkgs#llama-cpp
#   - Manual: Download from https://github.com/ggml-org/llama.cpp/releases
#
# ü§ñ Model requirements:
#   - Embedding model: nomic-embed-text-v1.5-q8.gguf (~150MB)
#   - Chat model: qwen2.5-7b-instruct-q4.gguf (~4.5GB)
#
# üìÅ Directory structure expected:
#   ./llama/llama-server.exe    # Binary
#   ./models/nomic-embed-text-v1.5-q8.gguf
#   ./models/qwen2.5-7b-instruct-q4.gguf
#
# ‚ö†Ô∏è  Troubleshooting: Check server startup logs for:
#   - "LLM service initialized in offline mode" ‚úÖ
#   - "Failed to create offline LLM service, falling back to MOCK mode" ‚ùå
#
# üîó Model downloads:
#   - Embedding: https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF/resolve/main/nomic-embed-text-v1.5.Q8_0.gguf
#   - Chat: https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_0.gguf

[llm.offline]
model_dir = "./models"                          # Directory containing GGUF model files
embed_model = "nomic-embed-text-v1.5-q8.gguf"  # Embedding model (~150MB)
# Download: https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF/resolve/main/nomic-embed-text-v1.5.Q8_0.gguf
chat_model = "qwen2.5-7b-instruct-q4.gguf"     # Chat model (~4.5GB)
# Download: https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_0.gguf

# Cloud Mode - API providers (sends data to external APIs)
# WARNING: Only use cloud mode if you understand the security implications
# [llm.cloud]
# provider = "gemini"                  # "gemini", "openai", "anthropic"
# api_key = "${QUAERO_LLM_CLOUD_API_KEY}"  # Use environment variable
# embed_model = "text-embedding-004"   # Cloud embedding model
# chat_model = "gemini-1.5-flash"      # Cloud chat model

# Audit Logging - Compliance and security
[llm.audit]
enabled = true      # Enable audit logging to SQLite
log_queries = false # Don't log query text (PII protection)

# =============================================================================
# Default Jobs Configuration
# =============================================================================
# Default jobs are system-managed scheduled tasks that run automatically.
# These jobs cannot be removed, only enabled/disabled.
# Minimum interval is 5 minutes.
# Schedule uses cron format: minute hour day month weekday
# Jobs run independently but not concurrently (mutex-protected).
#
# The `auto_start` option controls whether jobs execute immediately when the service starts.
# Set `auto_start = true` to run jobs on startup (useful for initial data collection).
# Set `auto_start = false` (default) to only run jobs on schedule or manual trigger.
# Auto-start is independent of the cron schedule.
#
# Examples:
# To collect data immediately on startup, set `auto_start = true` for crawl_and_collect.
# Jobs with `auto_start = false` will wait for their first scheduled run.
# Manual job triggering via API/UI works regardless of auto_start setting.

[jobs.crawl_and_collect]
enabled = true
auto_start = false  # Execute immediately on service startup (default: false)
schedule = "*/5 * * * *"  # Every 5 minutes
description = "Crawl and collect website data, store as markdown"

[jobs.scan_and_summarize]
enabled = true
auto_start = false  # Execute immediately on service startup (default: false)
schedule = "*/10 * * * *"  # Every 10 minutes
description = "Scan markdown documents and generate summaries with metadata"

# =============================================================================
# Crawler Configuration (Firecrawl-style HTML Scraping)
# =============================================================================
# Configure HTML scraping behavior for web page crawling.
# Follows Firecrawl architecture: scrape pages, convert to markdown, extract metadata.
# Technical parameters have sensible defaults hardcoded in the application.
# Only uncomment settings you want to override from defaults.
#
# Defaults: user_agent="Quaero/1.0 (Web Crawler)", max_concurrency=3,
#           request_delay=1s, random_delay=500ms, output_format="markdown"
# Env vars: QUAERO_CRAWLER_USER_AGENT, QUAERO_CRAWLER_MAX_CONCURRENCY, etc.

# [crawler]
# user_agent = "Quaero/1.0 (Web Crawler)"  # Default: Quaero/1.0 (Web Crawler)
# user_agent_rotation = true                # Default: true
# max_concurrency = 3                       # Default: 3
# request_delay = "1s"                      # Default: 1s
# random_delay = "500ms"                    # Default: 500ms
# request_timeout = "30s"                   # Default: 30s
# max_body_size = 10485760                  # Default: 10MB
# max_depth = 5                             # Default: 5
# follow_robots_txt = true                  # Default: true
# output_format = "markdown"                # Default: markdown (options: markdown, html, both)
# only_main_content = true                  # Default: true
# include_links = true                      # Default: true
# include_metadata = true                   # Default: true

# =============================================================================
# WebSocket Log Streaming Configuration
# =============================================================================
# Configure server-side filtering for real-time log streaming and event broadcasting to browser UI.
# Logs are filtered before broadcasting to reduce client load and network traffic.
# Technical parameters have sensible defaults hardcoded in the application.
# Only uncomment settings you want to override from defaults.
#
# Defaults: min_level="info", exclude_patterns=[...], allowed_events=[] (all), throttle_intervals={crawl_progress:1s, job_spawn:500ms}
# Env vars: QUAERO_WEBSOCKET_MIN_LEVEL, QUAERO_WEBSOCKET_EXCLUDE_PATTERNS, QUAERO_WEBSOCKET_ALLOWED_EVENTS, QUAERO_WEBSOCKET_THROTTLE_CRAWL_PROGRESS, QUAERO_WEBSOCKET_THROTTLE_JOB_SPAWN

# [websocket]
# min_level = "info"  # Minimum log level to broadcast ("debug", "info", "warn", "error")
# exclude_patterns = [  # Log message patterns to exclude from broadcasting
#     "WebSocket client connected",
#     "WebSocket client disconnected",
#     "HTTP request",
#     "HTTP response",
#     "Publishing Event",
#     "DEBUG: Memory writer entry",
# ]

# Event Filtering - Control which events are broadcast to WebSocket clients
# allowed_events = []  # Empty list allows all events (default)
# allowed_events = [   # Whitelist specific events (example)
#     "job_created",
#     "job_started",
#     "job_completed",
#     "job_failed",
#     "job_cancelled",
#     "crawl_progress",
#     "job_spawn",
# ]

# Event Throttling - Rate limit high-frequency events to prevent WebSocket flooding
# Throttling reduces network traffic and client load during large crawls (1000s of URLs)
# [websocket.throttle_intervals]
# crawl_progress = "1s"   # Max 1 crawl progress update per second per job (default)
# job_spawn = "500ms"     # Max 2 job spawn events per second (default)
