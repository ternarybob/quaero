# Quaero Configuration
# ====================
#
# This file contains ONLY user-facing configuration settings.
# Technical parameters (cache sizes, timeouts, dimensions, etc.) have sensible
# defaults hardcoded in the application and should not be modified unless you
# are debugging or have specific requirements.
#
# Configuration Load Order (priority from lowest to highest):
#   1. Defaults (hardcoded in application)
#   2. TOML file (this file)
#   3. Environment variables (QUAERO_*)
#   4. Command line flags (--port, --host, --config)
#
# Only uncomment settings you want to override from defaults.

# =============================================================================
# Environment Configuration
# =============================================================================
# Controls environment mode: "development" or "production"
# Production mode rejects test URLs (localhost, 127.0.0.1, etc.) for safety
# Default: development (allows test URLs)
# Env vars: QUAERO_ENV, GO_ENV (highest priority)

environment = "development"  # "development" or "production"

# =============================================================================
# Server Configuration
# =============================================================================
# Defaults: port=8080, host="localhost"
# CLI flags: --port, --host (highest priority)
# Env vars: QUAERO_SERVER_PORT, QUAERO_SERVER_HOST

[server]
# port = 8080         # Default: 8080
# host = "localhost"  # Default: localhost

# =============================================================================
# Data Sources Configuration
# =============================================================================
# Configure which sources to scrape and what projects/spaces to include.
# These are user-specific and should be uncommented and customized.

[sources.confluence]
enabled = true
spaces = ["TEAM", "DOCS"]  # Customize: Your Confluence spaces

[sources.jira]
enabled = true
projects = ["DATA", "ENG"]  # Customize: Your Jira projects

[sources.github]
enabled = true
token = "${GITHUB_TOKEN}"  # Use environment variable for security
repos = ["your-org/repo1"] # Customize: Your GitHub repositories

# =============================================================================
# Storage Configuration
# =============================================================================
# Defaults: path="./data/quaero.db"
# Env vars: QUAERO_SQLITE_PATH

[storage.sqlite]
# path = "./data/quaero.db"  # Default: ./data/quaero.db

[storage.filesystem]
# images = "./data/images"           # Default: ./data/images
# attachments = "./data/attachments" # Default: ./data/attachments

# =============================================================================
# LLM Configuration
# =============================================================================
# Two modes available: "offline" (local, no network) or "cloud" (API-based)
# Default: offline (secure by default)
# Env var: QUAERO_LLM_MODE

[llm]
mode = "offline"  # "offline" or "cloud"

# Offline Mode - Local models via llama-cli (100% local, no network calls)
[llm.offline]
model_dir = "./models"                          # Directory containing GGUF model files
embed_model = "nomic-embed-text-v1.5-q8.gguf"  # Embedding model (~150MB)
chat_model = "qwen2.5-7b-instruct-q4.gguf"     # Chat model (~4.5GB)

# Cloud Mode - API providers (sends data to external APIs)
# WARNING: Only use cloud mode if you understand the security implications
# [llm.cloud]
# provider = "gemini"                  # "gemini", "openai", "anthropic"
# api_key = "${QUAERO_LLM_CLOUD_API_KEY}"  # Use environment variable
# embed_model = "text-embedding-004"   # Cloud embedding model
# chat_model = "gemini-1.5-flash"      # Cloud chat model

# Audit Logging - Compliance and security
[llm.audit]
enabled = true      # Enable audit logging to SQLite
log_queries = false # Don't log query text (PII protection)

# =============================================================================
# Default Jobs Configuration
# =============================================================================
# Default jobs are system-managed scheduled tasks that run automatically.
# These jobs cannot be removed, only enabled/disabled.
# Minimum interval is 5 minutes.
# Schedule uses cron format: minute hour day month weekday
# Jobs run independently but not concurrently (mutex-protected).
#
# The `auto_start` option controls whether jobs execute immediately when the service starts.
# Set `auto_start = true` to run jobs on startup (useful for initial data collection).
# Set `auto_start = false` (default) to only run jobs on schedule or manual trigger.
# Auto-start is independent of the cron schedule.
#
# Examples:
# To collect data immediately on startup, set `auto_start = true` for crawl_and_collect.
# Jobs with `auto_start = false` will wait for their first scheduled run.
# Manual job triggering via API/UI works regardless of auto_start setting.

[jobs.crawl_and_collect]
enabled = true
auto_start = false  # Execute immediately on service startup (default: false)
schedule = "*/5 * * * *"  # Every 5 minutes
description = "Crawl and collect website data, store as markdown"

[jobs.scan_and_summarize]
enabled = true
auto_start = false  # Execute immediately on service startup (default: false)
schedule = "*/10 * * * *"  # Every 10 minutes
description = "Scan markdown documents and generate summaries with metadata"

# =============================================================================
# Crawler Configuration (Firecrawl-style HTML Scraping)
# =============================================================================
# Configure HTML scraping behavior for web page crawling.
# Follows Firecrawl architecture: scrape pages, convert to markdown, extract metadata.
# Technical parameters have sensible defaults hardcoded in the application.
# Only uncomment settings you want to override from defaults.
#
# Defaults: user_agent="Quaero/1.0 (Web Crawler)", max_concurrency=3,
#           request_delay=1s, random_delay=500ms, output_format="markdown"
# Env vars: QUAERO_CRAWLER_USER_AGENT, QUAERO_CRAWLER_MAX_CONCURRENCY, etc.

# [crawler]
# user_agent = "Quaero/1.0 (Web Crawler)"  # Default: Quaero/1.0 (Web Crawler)
# user_agent_rotation = true                # Default: true
# max_concurrency = 3                       # Default: 3
# request_delay = "1s"                      # Default: 1s
# random_delay = "500ms"                    # Default: 500ms
# request_timeout = "30s"                   # Default: 30s
# max_body_size = 10485760                  # Default: 10MB
# max_depth = 5                             # Default: 5
# follow_robots_txt = true                  # Default: true
# output_format = "markdown"                # Default: markdown (options: markdown, html, both)
# only_main_content = true                  # Default: true
# include_links = true                      # Default: true
# include_metadata = true                   # Default: true

# =============================================================================
# WebSocket Log Streaming Configuration
# =============================================================================
# Configure server-side filtering for real-time log streaming to browser UI.
# Logs are filtered before broadcasting to reduce client load and network traffic.
# Technical parameters have sensible defaults hardcoded in the application.
# Only uncomment settings you want to override from defaults.
#
# Defaults: min_level="info", exclude_patterns=["WebSocket client", "HTTP request", ...]
# Env vars: QUAERO_WEBSOCKET_MIN_LEVEL, QUAERO_WEBSOCKET_EXCLUDE_PATTERNS

# [websocket]
# min_level = "info"  # Minimum log level to broadcast ("debug", "info", "warn", "error")
# exclude_patterns = [  # Log message patterns to exclude from broadcasting
#     "WebSocket client connected",
#     "WebSocket client disconnected",
#     "HTTP request",
#     "HTTP response",
#     "Publishing Event",
# ]
