{
  "task": "Validate events service and refactor logging architecture",
  "folder": "validate-events-service-and-logging-architecture",
  "complexity": "high",
  "estimated_steps": 10,
  "current_state_analysis": {
    "events_service": {
      "status": "IMPLEMENTED AND ACTIVELY USED",
      "location": "internal/services/events/event_service.go",
      "implementation": "Pub/sub pattern with Subscribe/Unsubscribe/Publish methods",
      "initialization": "Created early in app.go:121 (before WebSocketHandler and LogService)",
      "subscribers": [
        "WebSocketHandler - subscribes to crawler events (crawl_progress, status_changed, job_spawn, crawler_job_progress, crawler_job_log)",
        "EventSubscriber (websocket_events.go) - subscribes to job lifecycle events (job_created, job_started, job_completed, job_failed, job_cancelled, job_spawn)",
        "StatusService - subscribes to crawler events",
        "CrawlerService - likely publishes events (needs verification)"
      ],
      "event_types": [
        "EventCollectionTriggered",
        "EventEmbeddingTriggered",
        "EventDocumentForceSync",
        "EventCrawlProgress",
        "EventStatusChanged",
        "EventSourceCreated/Updated/Deleted",
        "EventJobProgress",
        "EventJobSpawn",
        "EventJobCreated/Started/Completed/Failed/Cancelled",
        "crawler_job_progress (custom)",
        "crawler_job_log (custom)"
      ],
      "usage_flow": "Services publish events -> EventService dispatches -> Subscribers handle -> WebSocket broadcasts to UI",
      "assessment": "CRITICAL COMPONENT - Used extensively for real-time UI updates and service coordination"
    },
    "logging_architecture": {
      "status": "SOPHISTICATED MULTI-LAYER SYSTEM",
      "primary_logger": "github.com/ternarybob/arbor (structured logging)",
      "log_service": {
        "location": "internal/logs/service.go",
        "initialization": "Early in app.go:128 (before services init)",
        "features": [
          "Arbor context channel integration (logBatchChannel)",
          "Consumer goroutine for processing log batches",
          "Correlation ID support (WithCorrelationId)",
          "Groups logs by jobID for batch database writes",
          "Concurrent dispatch to WebSocket (non-blocking)",
          "Graceful shutdown with context cancellation",
          "Database persistence via JobLogStorage",
          "K-way merge for aggregated parent-child log retrieval",
          "Cursor-based pagination support"
        ],
        "storage": "SQLite job_logs table with full_timestamp, level, message, associated_job_id",
        "channel_capacity": 10,
        "correlation_flow": "Logger.WithCorrelationId(jobID) -> Arbor sends batches to channel -> Consumer processes -> DB + WebSocket"
      },
      "websocket_handler": {
        "log_methods": [
          "BroadcastLog(entry) - broadcasts LogEntry to all clients",
          "StreamCrawlerJobLog(jobID, level, message, metadata) - enhanced crawler logs",
          "SendLog(level, message) - helper for simple log broadcasting"
        ],
        "event_subscriptions": [
          "crawler_job_log event -> StreamCrawlerJobLog",
          "crawler_job_progress event -> BroadcastCrawlerJobProgress"
        ]
      },
      "current_implementation": "ALREADY IMPLEMENTS USER'S VISION",
      "assessment": "LogService is the single unified service using arbor channel logger with goroutine that buffers, analyzes, and dispatches appropriately"
    },
    "ui_integration": {
      "status": "COMPREHENSIVE REAL-TIME UPDATES",
      "websocket_endpoint": "/ws",
      "message_types": [
        "log - Individual log entries",
        "crawler_job_log - Enhanced crawler logs with metadata",
        "job_status_change - Job lifecycle events",
        "job_spawn - Child job creation events",
        "crawler_job_progress - Detailed progress updates",
        "crawl_progress - Legacy crawler progress",
        "app_status - Application state changes",
        "queue_stats - Queue statistics (disabled)",
        "status - Server status heartbeat",
        "auth - Authentication updates"
      ],
      "ui_pages": {
        "queue.html": "Real-time job monitoring with logs and status",
        "job.html": "Individual job details with aggregated logs",
        "jobs.html": "Job definition management",
        "chat.html": "Chat interface",
        "documents.html": "Document browser",
        "search.html": "Search interface"
      },
      "event_flow_to_ui": "Service -> EventService.Publish -> EventSubscriber/WebSocketHandler -> BroadcastXXX -> WebSocket clients -> Alpine.js updates DOM",
      "assessment": "FULLY FUNCTIONAL - Events reach UI via WebSocket with comprehensive filtering and throttling"
    },
    "correlation_id_usage": {
      "status": "IMPLEMENTED AND USED EXTENSIVELY",
      "implementation": "arbor.ILogger.WithCorrelationId(jobID) creates job-specific logger",
      "usage_locations": [
        "EnhancedCrawlerExecutor - uses parentID for log aggregation",
        "JobExecutor - creates context loggers for job execution",
        "ParentJobExecutor - monitors parent jobs with correlation",
        "DatabaseMaintenanceExecutor - job-scoped logging",
        "Various step executors - use correlation for tracing"
      ],
      "storage": "CorrelationID stored as AssociatedJobID in job_logs table",
      "aggregation": "GetAggregatedLogs supports parent-child log retrieval with k-way merge",
      "pattern": "Parent jobs use their own ID, child jobs use root parent ID for unified log viewing",
      "assessment": "WELL IMPLEMENTED - Context/correlation IDs are central to the logging architecture"
    },
    "redundancies": [
      {
        "type": "Duplicate event handling",
        "location": "WebSocketHandler.SubscribeToCrawlerEvents AND EventSubscriber",
        "description": "WebSocketHandler subscribes to crawler events directly, while EventSubscriber also subscribes to job events. Some overlap in functionality.",
        "impact": "Medium - Creates dual subscription paths but both are used",
        "recommendation": "Consider consolidating into EventSubscriber pattern for all events"
      },
      {
        "type": "Multiple log broadcast methods",
        "location": "WebSocketHandler",
        "methods": ["BroadcastLog", "StreamCrawlerJobLog", "SendLog"],
        "description": "Three different methods for broadcasting logs with overlapping functionality",
        "impact": "Low - Each serves slightly different purpose but could be unified",
        "recommendation": "Consider single BroadcastLog with optional metadata parameter"
      },
      {
        "type": "Legacy crawl_progress event",
        "location": "EventCrawlProgress vs crawler_job_progress",
        "description": "Two similar progress event types (legacy and new)",
        "impact": "Low - crawler_job_progress is more comprehensive",
        "recommendation": "Migrate remaining EventCrawlProgress usage to crawler_job_progress and deprecate"
      },
      {
        "type": "Queue stats broadcaster",
        "location": "app.go:607-638",
        "description": "Queue stats broadcaster goroutine is commented out with TODO",
        "impact": "Medium - Dead code that should be removed or re-enabled",
        "recommendation": "Either implement properly or remove commented code"
      }
    ],
    "gaps": [
      "No structured logging levels configuration (debug/info/warn/error filtering)",
      "Log retention policy not defined (logs grow indefinitely in database)",
      "No log rotation or archival strategy",
      "Missing log level filtering in WebSocket broadcast (sends all levels to UI)",
      "No rate limiting on log broadcasts (potential WebSocket flooding)",
      "EventService lacks metrics/observability (event count, subscriber count, errors)",
      "No circuit breaker for log channel overflow (could block on channel full)",
      "Missing log aggregation API endpoint documentation",
      "No log export functionality (for analysis/debugging)",
      "Correlation ID not propagated through all service layers consistently"
    ]
  },
  "steps": [
    {
      "id": 1,
      "task": "Validate EventService is actively used by services and reaches UI",
      "rationale": "Verify that EventService is not redundant and is essential for real-time updates",
      "dependencies": [],
      "validation_criteria": [
        "Trace event publication from at least 3 different services",
        "Verify WebSocket messages reach browser clients",
        "Confirm EventSubscriber processes job lifecycle events",
        "Validate UI receives and displays events in real-time"
      ],
      "artifacts": [
        "Event flow diagram (service -> EventService -> WebSocket -> UI)",
        "List of all event publishers and subscribers",
        "WebSocket message trace log"
      ],
      "risk_level": "low",
      "findings": "EventService is CRITICAL - used by crawler, job executors, status service. Events flow to UI via WebSocket. NOT redundant."
    },
    {
      "id": 2,
      "task": "Document current LogService architecture and validate it matches user's vision",
      "rationale": "User wants 'single service for context logging using arbor channel logger with goroutine that buffers, analyzes, and dispatches' - verify this exists",
      "dependencies": [1],
      "validation_criteria": [
        "LogService uses arbor context channel (GetChannel)",
        "Consumer goroutine processes batches from channel",
        "Logs are grouped by jobID for batch writes",
        "Correlation IDs are used throughout",
        "Logs dispatched to both database and WebSocket"
      ],
      "artifacts": [
        "LogService architecture diagram",
        "Correlation ID flow documentation",
        "Log dispatch flow (arbor -> channel -> consumer -> DB/WebSocket)"
      ],
      "risk_level": "low",
      "findings": "LogService ALREADY IMPLEMENTS user's vision - single service, arbor channel, goroutine consumer, context-based routing. No refactor needed."
    },
    {
      "id": 3,
      "task": "Analyze crawler job logging patterns and correlation ID usage",
      "rationale": "User wants crawler jobs to use context/correlationID (crawler-{parentid}), save to logging table, send filtered output to WebSocket",
      "dependencies": [2],
      "validation_criteria": [
        "EnhancedCrawlerExecutor uses WithCorrelationId(parentID)",
        "Logs saved to job_logs table with associated_job_id",
        "WebSocket receives crawler logs via BroadcastLog",
        "Parent-child log aggregation works correctly"
      ],
      "artifacts": [
        "Crawler logging flow diagram",
        "Correlation ID pattern documentation",
        "GetAggregatedLogs k-way merge explanation"
      ],
      "risk_level": "low",
      "findings": "Crawler logging FULLY IMPLEMENTED - uses parentID correlation, saves to DB, broadcasts to WebSocket, supports aggregation."
    },
    {
      "id": 4,
      "task": "Identify and document redundant event handling code",
      "rationale": "Consolidate duplicate event subscriptions and broadcasting methods",
      "dependencies": [1],
      "validation_criteria": [
        "List all WebSocket event subscriptions",
        "Identify overlapping functionality",
        "Document which subscriptions are actually used by UI",
        "Propose consolidation strategy"
      ],
      "artifacts": [
        "Event subscription audit",
        "Redundancy elimination plan",
        "Proposed unified event handling pattern"
      ],
      "risk_level": "medium",
      "recommended_actions": [
        "Consolidate WebSocketHandler.SubscribeToCrawlerEvents into EventSubscriber pattern",
        "Unify BroadcastLog, StreamCrawlerJobLog, SendLog into single method with metadata",
        "Deprecate EventCrawlProgress in favor of crawler_job_progress",
        "Remove or complete queue stats broadcaster (app.go:607-638)"
      ]
    },
    {
      "id": 5,
      "task": "Implement log level filtering and rate limiting",
      "rationale": "Prevent WebSocket flooding and allow UI to filter log levels",
      "dependencies": [2, 3],
      "validation_criteria": [
        "WebSocket config supports log level filtering",
        "Rate limiting applied to high-frequency events",
        "UI can request specific log levels via API",
        "Log broadcast respects client preferences"
      ],
      "artifacts": [
        "internal/common/config.go - Add log level filtering config",
        "internal/handlers/websocket.go - Implement level filtering",
        "internal/logs/service.go - Add level-based dispatch",
        "API endpoint for log level preferences"
      ],
      "risk_level": "medium",
      "recommended_implementation": {
        "config": "Add [websocket.log_filters] with min_level and excluded_levels",
        "service": "LogService consumer checks level before dispatch",
        "websocket": "BroadcastLog accepts level parameter and filters",
        "rate_limiting": "Extend existing throttlers to cover all high-frequency events"
      }
    },
    {
      "id": 6,
      "task": "Add log retention and archival strategy",
      "rationale": "Prevent unbounded database growth from logs",
      "dependencies": [2],
      "validation_criteria": [
        "Config defines log retention period (e.g., 30 days)",
        "Cleanup job removes old logs on schedule",
        "Archived logs optionally exported to files",
        "Database size remains bounded"
      ],
      "artifacts": [
        "internal/common/config.go - Add [logging.retention] config",
        "internal/jobs/executor/log_cleanup_executor.go - Create cleanup executor",
        "internal/storage/sqlite/job_log_storage.go - Add DeleteLogsBefore method",
        "Scheduled cleanup job in scheduler service"
      ],
      "risk_level": "low",
      "recommended_implementation": {
        "retention_period": "30 days default",
        "cleanup_schedule": "Daily at 2 AM",
        "archival_format": "Optional JSON export before deletion",
        "cleanup_job_type": "log_cleanup (new job type)"
      }
    },
    {
      "id": 7,
      "task": "Enhance EventService with observability metrics",
      "rationale": "Track event publication, subscription counts, errors for monitoring",
      "dependencies": [1],
      "validation_criteria": [
        "EventService tracks events published count",
        "Subscriber count per event type available",
        "Failed handler executions logged with details",
        "Metrics exposed via API or logs"
      ],
      "artifacts": [
        "internal/services/events/event_service.go - Add metrics fields",
        "internal/services/events/metrics.go - Metrics aggregation",
        "GET /api/events/metrics - New API endpoint",
        "Prometheus-compatible metrics format"
      ],
      "risk_level": "low",
      "recommended_implementation": {
        "metrics": [
          "events_published_total (counter by event_type)",
          "event_subscribers_current (gauge by event_type)",
          "event_handler_errors_total (counter by event_type)",
          "event_handler_duration_seconds (histogram)"
        ],
        "storage": "In-memory counters with periodic logging",
        "api_endpoint": "GET /api/events/metrics returns JSON"
      }
    },
    {
      "id": 8,
      "task": "Create comprehensive logging architecture documentation",
      "rationale": "Document the sophisticated logging system for future developers",
      "dependencies": [2, 3, 4],
      "validation_criteria": [
        "Architecture diagram shows all components",
        "Flow diagrams for log dispatch paths",
        "Correlation ID usage patterns documented",
        "API documentation for log aggregation endpoints",
        "Examples for adding new log sources"
      ],
      "artifacts": [
        "docs/architecture/LOGGING_ARCHITECTURE.md - Comprehensive guide",
        "docs/architecture/diagrams/logging-flow.mermaid - Visual flow",
        "docs/api/LOG_AGGREGATION_API.md - API documentation",
        "CLAUDE.md updates - Add logging patterns section"
      ],
      "risk_level": "low"
    },
    {
      "id": 9,
      "task": "Implement log export functionality for debugging",
      "rationale": "Enable developers to export logs for offline analysis",
      "dependencies": [2, 6],
      "validation_criteria": [
        "API endpoint exports logs as JSON/CSV",
        "Supports filtering by job_id, level, date range",
        "Includes correlation ID in export",
        "Respects pagination limits"
      ],
      "artifacts": [
        "internal/handlers/log_handler.go - New handler",
        "GET /api/logs/export - New endpoint",
        "Export formats: JSON, CSV, plain text",
        "Streaming export for large datasets"
      ],
      "risk_level": "low",
      "recommended_implementation": {
        "endpoint": "GET /api/logs/export?job_id=X&level=error&format=json",
        "formats": ["json", "csv", "txt"],
        "streaming": "Use chunked transfer encoding for large exports",
        "filters": "job_id, parent_id, level, start_date, end_date, limit"
      }
    },
    {
      "id": 10,
      "task": "Validate and update UI to leverage enhanced logging features",
      "rationale": "Ensure queue.html and job.html pages use all available logging features",
      "dependencies": [5, 9],
      "validation_criteria": [
        "Queue page displays real-time logs with level filtering",
        "Job page shows aggregated parent-child logs",
        "Log export button available in UI",
        "Log level filter controls functional",
        "Auto-scroll respects user scroll position"
      ],
      "artifacts": [
        "pages/queue.html - Add log level filter UI",
        "pages/job.html - Verify aggregated logs display",
        "pages/static/common.js - Log export function",
        "Alpine.js components for log filtering"
      ],
      "risk_level": "medium",
      "recommended_implementation": {
        "log_level_filter": "Dropdown: All, Debug, Info, Warn, Error",
        "export_button": "Download logs as JSON/CSV",
        "auto_scroll": "Follow logs checkbox with scroll lock detection",
        "aggregated_view": "Tree view showing parent-child hierarchy"
      }
    }
  ],
  "constraints": [
    "Must not break existing real-time UI updates",
    "Must maintain backward compatibility with current WebSocket clients",
    "Must preserve correlation ID patterns (parent jobs use own ID, children use root parent)",
    "Must not introduce breaking changes to EventService interface",
    "Must follow CLAUDE.md conventions (arbor logging, no fmt.Println, no global state)",
    "Must use build scripts for all testing and validation",
    "Must maintain TestMain fixture for test lifecycle management",
    "Must not modify EventService or LogService core functionality (already optimal)",
    "Changes should focus on cleanup, documentation, and enhancements (not refactoring)"
  ],
  "success_criteria": [
    "EventService validated as critical component (not redundant)",
    "LogService architecture documented and confirmed as matching user's vision",
    "Crawler job logging patterns validated with correlation IDs",
    "Redundant code identified and elimination plan created",
    "Log level filtering and rate limiting implemented",
    "Log retention policy established and cleanup job created",
    "EventService observability metrics added",
    "Comprehensive logging architecture documentation written",
    "Log export functionality implemented for debugging",
    "UI updated to leverage enhanced logging features",
    "All changes validated through build script and tests",
    "No regression in real-time UI updates or job monitoring"
  ],
  "key_findings": {
    "events_service_status": "CRITICAL AND ACTIVELY USED - Not redundant, essential for real-time UI",
    "logging_architecture_status": "ALREADY IMPLEMENTS USER'S VISION - LogService is the single unified service with arbor channel, goroutine consumer, and intelligent dispatch",
    "correlation_id_status": "WELL IMPLEMENTED - Used extensively throughout crawler jobs and job executors",
    "redundancy_count": 4,
    "gap_count": 10,
    "overall_assessment": "The architecture is sophisticated and well-designed. User's request for 'single service for context logging using arbor channel logger with goroutine that buffers, analyzes, and dispatches' is ALREADY IMPLEMENTED in LogService. Focus should be on cleanup, documentation, and enhancement rather than major refactoring.",
    "recommended_focus": [
      "Document existing architecture (it's excellent but undocumented)",
      "Clean up redundant event subscriptions",
      "Add log retention and export features",
      "Enhance observability with metrics",
      "Improve UI log filtering capabilities"
    ]
  },
  "validation_rules_applied": [
    "no_root_binaries - Build script validation only",
    "use_build_script - All testing via scripts/build.ps1",
    "tests_in_correct_dir - No test creation in this analysis phase",
    "tests_must_pass - Validation will use existing test suite",
    "code_compiles - All changes must compile via build script",
    "follows_conventions - Arbor logging, no fmt.Println, structured logging"
  ]
}
