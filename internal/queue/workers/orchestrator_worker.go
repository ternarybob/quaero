// -----------------------------------------------------------------------
// OrchestratorWorker - AI-powered cognitive orchestration using LLM reasoning
// Receives a goal and available tools, dynamically plans and executes steps
// using a Planner-Executor-Reviewer loop.
// -----------------------------------------------------------------------

package workers

import (
	"context"
	"encoding/json"
	"fmt"
	"strings"
	"time"

	"github.com/google/uuid"
	"github.com/ternarybob/arbor"
	"github.com/ternarybob/quaero/internal/interfaces"
	"github.com/ternarybob/quaero/internal/models"
	"github.com/ternarybob/quaero/internal/queue"
	"github.com/ternarybob/quaero/internal/services/llm"
)

// Plan represents a dynamic execution plan generated by the LLM Planner
type Plan struct {
	Reasoning string     `json:"reasoning"`
	Steps     []PlanStep `json:"steps"`
}

// PlanStep represents a single step in the execution plan
type PlanStep struct {
	ID        string                 `json:"id"`
	Tool      string                 `json:"tool"`
	Params    map[string]interface{} `json:"params"`
	DependsOn []string               `json:"depends_on,omitempty"`
}

// PlanStepResult holds the result of executing a plan step
type PlanStepResult struct {
	StepID  string
	Tool    string
	Success bool
	Output  string
	Error   string
}

// plannerSystemPrompt is the system instruction for the Planner LLM
const plannerSystemPrompt = `You are an intelligent orchestration planner. Your job is to analyze a goal and create an execution plan using the available tools.

IMPORTANT RULES:
1. Output ONLY valid JSON - no markdown code blocks, no explanations before or after the JSON
2. Each step must use exactly one tool from the available_tools list
3. Steps can depend on other steps using the depends_on field
4. Use meaningful step IDs like "step_1_fetch_data", "step_2_analyze"
5. Params must match what the tool expects

OUTPUT FORMAT (JSON only):
{
  "reasoning": "Brief explanation of the plan",
  "steps": [
    {
      "id": "step_1",
      "tool": "tool_name",
      "params": {"key": "value"},
      "depends_on": []
    }
  ]
}

If no tools are available or the goal cannot be achieved, return:
{
  "reasoning": "Explanation of why no plan can be created",
  "steps": []
}`

// reviewerSystemPrompt is the system instruction for the Reviewer LLM
const reviewerSystemPrompt = `You are a quality reviewer for orchestration results. Analyze the execution results against the original goal.

IMPORTANT RULES:
1. Output ONLY valid JSON - no markdown code blocks, no explanations
2. Check if the goal was achieved based on the results
3. Identify any missing data or failures
4. If recovery is needed, suggest specific actions

OUTPUT FORMAT (JSON only):
{
  "goal_achieved": true/false,
  "confidence": 0.0-1.0,
  "summary": "Brief summary of results",
  "missing_data": ["list of missing items"],
  "recovery_actions": [
    {"tool": "tool_name", "params": {"key": "value"}, "reason": "why needed"}
  ]
}`

// ThinkingLevel represents the depth of LLM reasoning for orchestration
type ThinkingLevel string

const (
	ThinkingLevelMinimal ThinkingLevel = "MINIMAL" // Quick planning, minimal reasoning
	ThinkingLevelLow     ThinkingLevel = "LOW"     // Light reasoning, fast execution
	ThinkingLevelMedium  ThinkingLevel = "MEDIUM"  // Balanced reasoning (default)
	ThinkingLevelHigh    ThinkingLevel = "HIGH"    // Deep reasoning, thorough analysis
)

// OrchestratorWorker implements AI-powered cognitive orchestration.
// It uses LLM reasoning to dynamically plan and execute steps based on a goal.
// This is the "thinking" component that makes decisions about what to do.
//
// Configuration (step.config):
//   - goal (string, required): Natural language description of the desired outcome
//   - context_files ([]string, optional): Files to read for context
//   - available_tools ([]map, optional): Workers exposed as callable tools
//   - thinking_level (string, optional): MINIMAL, LOW, MEDIUM, HIGH (default: MEDIUM)
//   - output_schema (string, optional): Path to validation schema
//   - model_preference (string, optional): Model selection: auto, flash, pro
type OrchestratorWorker struct {
	documentStorage interfaces.DocumentStorage
	searchService   interfaces.SearchService
	kvStorage       interfaces.KeyValueStorage
	eventService    interfaces.EventService
	logger          arbor.ILogger
	jobMgr          *queue.Manager
	providerFactory *llm.ProviderFactory
	stepManager     interfaces.StepManager
}

// Compile-time assertion: OrchestratorWorker implements DefinitionWorker interface
var _ interfaces.DefinitionWorker = (*OrchestratorWorker)(nil)

// NewOrchestratorWorker creates a new orchestrator worker
func NewOrchestratorWorker(
	documentStorage interfaces.DocumentStorage,
	searchService interfaces.SearchService,
	kvStorage interfaces.KeyValueStorage,
	eventService interfaces.EventService,
	logger arbor.ILogger,
	jobMgr *queue.Manager,
	providerFactory *llm.ProviderFactory,
) *OrchestratorWorker {
	return &OrchestratorWorker{
		documentStorage: documentStorage,
		searchService:   searchService,
		kvStorage:       kvStorage,
		eventService:    eventService,
		logger:          logger,
		jobMgr:          jobMgr,
		providerFactory: providerFactory,
	}
}

// SetStepManager sets the step manager for executing tool calls.
// This is set after construction to avoid circular dependency during initialization.
func (w *OrchestratorWorker) SetStepManager(sm interfaces.StepManager) {
	w.stepManager = sm
}

// GetType returns WorkerTypeOrchestrator for the DefinitionWorker interface
func (w *OrchestratorWorker) GetType() models.WorkerType {
	return models.WorkerTypeOrchestrator
}

// ValidateConfig validates step configuration before execution.
// Checks for required fields and valid values.
func (w *OrchestratorWorker) ValidateConfig(step models.JobStep) error {
	config := step.Config
	if config == nil {
		return fmt.Errorf("step config is required for orchestrator")
	}

	// Validate required goal parameter
	goal, ok := config["goal"].(string)
	if !ok || strings.TrimSpace(goal) == "" {
		return fmt.Errorf("goal is required in orchestrator step config")
	}

	// Validate thinking_level if provided
	if level, ok := config["thinking_level"].(string); ok {
		levelUpper := strings.ToUpper(level)
		switch ThinkingLevel(levelUpper) {
		case ThinkingLevelMinimal, ThinkingLevelLow, ThinkingLevelMedium, ThinkingLevelHigh:
			// Valid
		default:
			return fmt.Errorf("invalid thinking_level '%s': must be MINIMAL, LOW, MEDIUM, or HIGH", level)
		}
	}

	// Validate available_tools format if provided
	if tools, ok := config["available_tools"]; ok {
		switch t := tools.(type) {
		case []interface{}:
			// Valid: array of tool definitions
			for i, tool := range t {
				if toolMap, ok := tool.(map[string]interface{}); ok {
					if _, hasName := toolMap["name"]; !hasName {
						return fmt.Errorf("available_tools[%d] must have a 'name' field", i)
					}
				} else {
					return fmt.Errorf("available_tools[%d] must be a map with 'name' and optional 'description'", i)
				}
			}
		case []map[string]interface{}:
			// Valid: typed array
		default:
			return fmt.Errorf("available_tools must be an array of tool definitions")
		}
	}

	return nil
}

// Init performs the initialization/setup phase for an orchestrator step.
// This is where we:
//   - Extract and validate configuration (goal, context, tools)
//   - Prepare the context for LLM planning
//   - Return metadata for CreateJobs
//
// The Init phase does NOT execute any planning - it only validates and prepares.
func (w *OrchestratorWorker) Init(ctx context.Context, step models.JobStep, jobDef models.JobDefinition) (*interfaces.WorkerInitResult, error) {
	config := step.Config
	if config == nil {
		return nil, fmt.Errorf("step config is required for orchestrator")
	}

	// Extract goal (required)
	goal, ok := config["goal"].(string)
	if !ok || strings.TrimSpace(goal) == "" {
		return nil, fmt.Errorf("goal is required in orchestrator step config")
	}

	// Extract thinking_level (optional, default: MEDIUM)
	thinkingLevel := ThinkingLevelMedium
	if level, ok := config["thinking_level"].(string); ok {
		thinkingLevel = ThinkingLevel(strings.ToUpper(level))
	}

	// Extract variables from job definition config (the standard pattern for user data)
	// Variables are defined in the [config] section of the job definition TOML
	var variables []map[string]interface{}
	if jobConfig := jobDef.Config; jobConfig != nil {
		if vars, ok := jobConfig["variables"].([]interface{}); ok {
			for _, v := range vars {
				if varMap, ok := v.(map[string]interface{}); ok {
					variables = append(variables, varMap)
				}
			}
		} else if vars, ok := jobConfig["variables"].([]map[string]interface{}); ok {
			variables = vars
		}
	}

	// Also extract benchmarks if present (for portfolio jobs)
	var benchmarks []map[string]interface{}
	if jobConfig := jobDef.Config; jobConfig != nil {
		if b, ok := jobConfig["benchmarks"].([]interface{}); ok {
			for _, v := range b {
				if bMap, ok := v.(map[string]interface{}); ok {
					benchmarks = append(benchmarks, bMap)
				}
			}
		} else if b, ok := jobConfig["benchmarks"].([]map[string]interface{}); ok {
			benchmarks = b
		}
	}

	// Extract available_tools (optional)
	var availableTools []map[string]interface{}
	if tools, ok := config["available_tools"].([]interface{}); ok {
		for _, t := range tools {
			if toolMap, ok := t.(map[string]interface{}); ok {
				availableTools = append(availableTools, toolMap)
			}
		}
	} else if tools, ok := config["available_tools"].([]map[string]interface{}); ok {
		availableTools = tools
	}

	// Extract model_preference (optional)
	modelPreference := "auto"
	if pref, ok := config["model_preference"].(string); ok {
		modelPreference = pref
	}

	w.logger.Info().
		Str("phase", "init").
		Str("step_name", step.Name).
		Str("goal", goal).
		Str("thinking_level", string(thinkingLevel)).
		Int("variables", len(variables)).
		Int("benchmarks", len(benchmarks)).
		Int("available_tools", len(availableTools)).
		Str("model_preference", modelPreference).
		Msg("Orchestrator worker initialized")

	// Create a single work item representing the orchestration task
	workItems := []interfaces.WorkItem{
		{
			ID:   "orchestration",
			Name: fmt.Sprintf("Orchestrate: %s", truncateString(goal, 50)),
			Type: "orchestrator",
			Config: map[string]interface{}{
				"goal": goal,
			},
		},
	}

	return &interfaces.WorkerInitResult{
		WorkItems:            workItems,
		TotalCount:           1,
		Strategy:             interfaces.ProcessingStrategyInline, // Synchronous execution for now
		SuggestedConcurrency: 1,
		Metadata: map[string]interface{}{
			"goal":             goal,
			"thinking_level":   string(thinkingLevel),
			"variables":        variables,
			"benchmarks":       benchmarks,
			"available_tools":  availableTools,
			"model_preference": modelPreference,
		},
	}, nil
}

// CreateJobs executes the orchestration logic using the Planner-Executor-Reviewer loop.
// 1. PLANNER: Uses LLM to create an execution plan based on goal and context
// 2. EXECUTOR: Executes plan steps using available tools (simulated for now)
// 3. REVIEWER: Verifies results and triggers recovery if needed
func (w *OrchestratorWorker) CreateJobs(ctx context.Context, step models.JobStep, jobDef models.JobDefinition, stepID string, initResult *interfaces.WorkerInitResult) (string, error) {
	// Call Init if not provided
	if initResult == nil {
		var err error
		initResult, err = w.Init(ctx, step, jobDef)
		if err != nil {
			return "", fmt.Errorf("failed to initialize orchestrator worker: %w", err)
		}
	}

	// Extract metadata from init result
	goal, _ := initResult.Metadata["goal"].(string)
	thinkingLevel, _ := initResult.Metadata["thinking_level"].(string)
	availableTools, _ := initResult.Metadata["available_tools"].([]map[string]interface{})
	variables, _ := initResult.Metadata["variables"].([]map[string]interface{})
	benchmarks, _ := initResult.Metadata["benchmarks"].([]map[string]interface{})
	modelPreference, _ := initResult.Metadata["model_preference"].(string)

	w.logger.Info().
		Str("phase", "run").
		Str("step_name", step.Name).
		Str("step_id", stepID).
		Str("goal", goal).
		Str("thinking_level", thinkingLevel).
		Int("available_tools", len(availableTools)).
		Int("variables", len(variables)).
		Int("benchmarks", len(benchmarks)).
		Msg("Starting orchestration")

	// Log step start for UI
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Orchestrator starting: goal='%s'", truncateString(goal, 100)))

		if len(availableTools) > 0 {
			toolNames := make([]string, 0, len(availableTools))
			for _, tool := range availableTools {
				if name, ok := tool["name"].(string); ok {
					toolNames = append(toolNames, name)
				}
			}
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("Available tools: %s", strings.Join(toolNames, ", ")))
		}
	}

	// =========================================================================
	// PHASE 1: PLANNER - Read variables and generate execution plan
	// =========================================================================
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Phase 1: PLANNER - Reading variables and generating plan...")
	}

	// Format variables as context for LLM
	contextContent := w.formatVariablesAsContext(variables, benchmarks)

	if len(variables) > 0 && w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Loaded %d variables, %d benchmarks", len(variables), len(benchmarks)))
	}

	// Generate execution plan using LLM
	plan, err := w.generatePlan(ctx, goal, contextContent, availableTools, thinkingLevel, modelPreference)
	if err != nil {
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "error", fmt.Sprintf("Planning failed: %v", err))
		}
		return "", fmt.Errorf("planning phase failed: %w", err)
	}

	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Plan generated: %s", truncateString(plan.Reasoning, 200)))
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Plan has %d steps", len(plan.Steps)))
	}

	// Log each planned step
	for i, planStep := range plan.Steps {
		if w.jobMgr != nil {
			paramsJSON, _ := json.Marshal(planStep.Params)
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("   Step %d: %s (tool: %s) params: %s", i+1, planStep.ID, planStep.Tool, string(paramsJSON)))
		}
	}

	// =========================================================================
	// PHASE 2: EXECUTOR - Execute plan steps
	// =========================================================================
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Phase 2: EXECUTOR - Executing plan steps...")
	}

	var results []PlanStepResult

	// Build tool lookup map for quick access
	toolLookup := make(map[string]map[string]interface{})
	for _, tool := range availableTools {
		if name, ok := tool["name"].(string); ok {
			toolLookup[name] = tool
		}
	}

	// Execute each plan step
	for _, planStep := range plan.Steps {
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("Executing step: %s (tool: %s)", planStep.ID, planStep.Tool))
		}

		var result PlanStepResult

		// Find the tool configuration
		toolConfig, toolFound := toolLookup[planStep.Tool]
		if !toolFound {
			result = PlanStepResult{
				StepID:  planStep.ID,
				Tool:    planStep.Tool,
				Success: false,
				Error:   fmt.Sprintf("Tool '%s' not found in available_tools", planStep.Tool),
			}
		} else if w.stepManager == nil {
			// Fallback to simulation if StepManager not available
			w.logger.Warn().
				Str("step_id", planStep.ID).
				Str("tool", planStep.Tool).
				Msg("StepManager not available, simulating tool execution")
			workerType, _ := toolConfig["worker"].(string)
			result = PlanStepResult{
				StepID:  planStep.ID,
				Tool:    planStep.Tool,
				Success: true,
				Output:  fmt.Sprintf("SIMULATED: Would invoke worker '%s' for tool '%s' (StepManager not configured)", workerType, planStep.Tool),
			}
		} else {
			// Execute tool via StepManager
			result = w.executeTool(ctx, planStep, toolConfig, jobDef, stepID)
		}

		results = append(results, result)

		if w.jobMgr != nil {
			if result.Success {
				w.jobMgr.AddJobLog(ctx, stepID, "info",
					fmt.Sprintf("Step %s completed: %s", planStep.ID, truncateString(result.Output, 100)))
			} else {
				w.jobMgr.AddJobLog(ctx, stepID, "warning",
					fmt.Sprintf("Step %s failed: %s", planStep.ID, result.Error))
			}
		}
	}

	// =========================================================================
	// PHASE 3: REVIEWER - Assess results and determine if goal was achieved
	// =========================================================================
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Phase 3: REVIEWER - Assessing results...")
	}

	review, err := w.reviewResults(ctx, goal, results, thinkingLevel)
	if err != nil {
		w.logger.Warn().Err(err).Msg("Review phase failed, continuing anyway")
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "warning",
				fmt.Sprintf("Review failed: %v", err))
		}
	} else {
		if w.jobMgr != nil {
			status := "OK"
			if !review.GoalAchieved {
				status = "INCOMPLETE"
			}
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("[%s] Review complete: Goal achieved=%v, Confidence=%.0f%%",
					status, review.GoalAchieved, review.Confidence*100))
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("Summary: %s", review.Summary))

			if len(review.MissingData) > 0 {
				w.jobMgr.AddJobLog(ctx, stepID, "warning",
					fmt.Sprintf("Missing data: %s", strings.Join(review.MissingData, ", ")))
			}

			if len(review.RecoveryActions) > 0 {
				w.jobMgr.AddJobLog(ctx, stepID, "info",
					fmt.Sprintf("Recovery actions suggested: %d", len(review.RecoveryActions)))
				// TODO: Implement recovery loop - re-run with suggested actions
			}
		}
	}

	// =========================================================================
	// SAVE OUTPUT DOCUMENT
	// =========================================================================
	// Build output content from plan and review results
	outputContent := w.buildOutputContent(goal, plan, results, review)

	// Save output document with tags from step config
	if err := w.saveOutputDocument(ctx, stepID, step, jobDef, outputContent); err != nil {
		w.logger.Warn().Err(err).Msg("Failed to save orchestrator output document")
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "warning", fmt.Sprintf("Failed to save output document: %v", err))
		}
	} else {
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "info", "Output document saved")
		}
	}

	// =========================================================================
	// COMPLETE
	// =========================================================================
	w.logger.Info().
		Str("phase", "complete").
		Str("step_name", step.Name).
		Str("step_id", stepID).
		Bool("goal_achieved", review != nil && review.GoalAchieved).
		Msg("Orchestration complete")

	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Orchestration complete")
	}

	return stepID, nil
}

// ReturnsChildJobs returns false since orchestrator currently executes inline.
// Future implementation may spawn child jobs for parallel tool execution.
func (w *OrchestratorWorker) ReturnsChildJobs() bool {
	return false
}

// truncateString truncates a string to maxLen characters, adding "..." if truncated
func truncateString(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	if maxLen <= 3 {
		return s[:maxLen]
	}
	return s[:maxLen-3] + "..."
}

// formatVariablesAsContext formats variables and benchmarks from the job definition config
// as a context string for the LLM planner. This follows the standard job-definition pattern
// where user data is declared in [config] variables.
func (w *OrchestratorWorker) formatVariablesAsContext(variables []map[string]interface{}, benchmarks []map[string]interface{}) string {
	if len(variables) == 0 && len(benchmarks) == 0 {
		return ""
	}

	var sb strings.Builder

	// Format variables (stocks, holdings, etc.)
	if len(variables) > 0 {
		sb.WriteString("--- Variables (from job definition) ---\n")
		jsonBytes, err := json.MarshalIndent(map[string]interface{}{"items": variables}, "", "  ")
		if err == nil {
			sb.WriteString(string(jsonBytes))
		} else {
			// Fallback to simple format
			for i, v := range variables {
				sb.WriteString(fmt.Sprintf("%d. %v\n", i+1, v))
			}
		}
	}

	// Format benchmarks if present
	if len(benchmarks) > 0 {
		if sb.Len() > 0 {
			sb.WriteString("\n\n")
		}
		sb.WriteString("--- Benchmarks ---\n")
		jsonBytes, err := json.MarshalIndent(map[string]interface{}{"benchmarks": benchmarks}, "", "  ")
		if err == nil {
			sb.WriteString(string(jsonBytes))
		} else {
			for i, b := range benchmarks {
				sb.WriteString(fmt.Sprintf("%d. %v\n", i+1, b))
			}
		}
	}

	return sb.String()
}

// formatToolsForPrompt formats available tools as a string for the LLM prompt
func (w *OrchestratorWorker) formatToolsForPrompt(tools []map[string]interface{}) string {
	if len(tools) == 0 {
		return "No tools available."
	}

	var sb strings.Builder
	sb.WriteString("Available Tools:\n")

	for i, tool := range tools {
		name, _ := tool["name"].(string)
		desc, _ := tool["description"].(string)
		worker, _ := tool["worker"].(string)

		sb.WriteString(fmt.Sprintf("%d. %s", i+1, name))
		if worker != "" {
			sb.WriteString(fmt.Sprintf(" (worker: %s)", worker))
		}
		if desc != "" {
			sb.WriteString(fmt.Sprintf("\n   Description: %s", desc))
		}
		sb.WriteString("\n")
	}

	return sb.String()
}

// generatePlan uses LLM to create an execution plan based on goal and context
func (w *OrchestratorWorker) generatePlan(ctx context.Context, goal string, contextContent string, tools []map[string]interface{}, thinkingLevel string, modelPreference string) (*Plan, error) {
	// Build the user prompt
	var userPrompt strings.Builder
	userPrompt.WriteString("GOAL:\n")
	userPrompt.WriteString(goal)
	userPrompt.WriteString("\n\n")

	if contextContent != "" {
		userPrompt.WriteString("CONTEXT:\n")
		userPrompt.WriteString(contextContent)
		userPrompt.WriteString("\n\n")
	}

	userPrompt.WriteString(w.formatToolsForPrompt(tools))
	userPrompt.WriteString("\n\nCreate an execution plan to achieve the goal. Output ONLY valid JSON.")

	// Determine model based on preference
	var model string
	switch strings.ToLower(modelPreference) {
	case "flash":
		model = "gemini-2.0-flash"
	case "pro":
		model = "gemini-2.0-pro"
	default:
		model = "" // Use provider default
	}

	// Call LLM
	request := &llm.ContentRequest{
		Messages: []interfaces.Message{
			{Role: "user", Content: userPrompt.String()},
		},
		Model:             model,
		SystemInstruction: plannerSystemPrompt,
		ThinkingLevel:     thinkingLevel,
	}

	response, err := w.providerFactory.GenerateContent(ctx, request)
	if err != nil {
		return nil, fmt.Errorf("LLM planning failed: %w", err)
	}

	// Parse JSON response
	responseText := strings.TrimSpace(response.Text)

	// Remove markdown code blocks if present
	responseText = strings.TrimPrefix(responseText, "```json")
	responseText = strings.TrimPrefix(responseText, "```")
	responseText = strings.TrimSuffix(responseText, "```")
	responseText = strings.TrimSpace(responseText)

	var plan Plan
	if err := json.Unmarshal([]byte(responseText), &plan); err != nil {
		w.logger.Error().
			Str("response", truncateString(responseText, 500)).
			Err(err).
			Msg("Failed to parse LLM plan response")
		return nil, fmt.Errorf("failed to parse plan JSON: %w", err)
	}

	w.logger.Info().
		Str("reasoning", plan.Reasoning).
		Int("steps", len(plan.Steps)).
		Msg("Generated execution plan")

	return &plan, nil
}

// ReviewResult represents the reviewer's assessment
type ReviewResult struct {
	GoalAchieved    bool                     `json:"goal_achieved"`
	Confidence      float64                  `json:"confidence"`
	Summary         string                   `json:"summary"`
	MissingData     []string                 `json:"missing_data"`
	RecoveryActions []map[string]interface{} `json:"recovery_actions"`
}

// reviewResults uses LLM to assess if the goal was achieved
func (w *OrchestratorWorker) reviewResults(ctx context.Context, goal string, results []PlanStepResult, thinkingLevel string) (*ReviewResult, error) {
	// Format results for review
	var resultsText strings.Builder
	resultsText.WriteString("EXECUTION RESULTS:\n\n")

	for _, r := range results {
		resultsText.WriteString(fmt.Sprintf("Step: %s (tool: %s)\n", r.StepID, r.Tool))
		if r.Success {
			resultsText.WriteString(fmt.Sprintf("Status: SUCCESS\nOutput: %s\n\n", truncateString(r.Output, 1000)))
		} else {
			resultsText.WriteString(fmt.Sprintf("Status: FAILED\nError: %s\n\n", r.Error))
		}
	}

	// Build review prompt
	userPrompt := fmt.Sprintf("ORIGINAL GOAL:\n%s\n\n%s\n\nReview these results and determine if the goal was achieved. Output ONLY valid JSON.",
		goal, resultsText.String())

	request := &llm.ContentRequest{
		Messages: []interfaces.Message{
			{Role: "user", Content: userPrompt},
		},
		SystemInstruction: reviewerSystemPrompt,
		ThinkingLevel:     thinkingLevel,
	}

	response, err := w.providerFactory.GenerateContent(ctx, request)
	if err != nil {
		return nil, fmt.Errorf("LLM review failed: %w", err)
	}

	// Parse JSON response
	responseText := strings.TrimSpace(response.Text)
	responseText = strings.TrimPrefix(responseText, "```json")
	responseText = strings.TrimPrefix(responseText, "```")
	responseText = strings.TrimSuffix(responseText, "```")
	responseText = strings.TrimSpace(responseText)

	var review ReviewResult
	if err := json.Unmarshal([]byte(responseText), &review); err != nil {
		w.logger.Warn().
			Str("response", truncateString(responseText, 500)).
			Err(err).
			Msg("Failed to parse review response, assuming goal not achieved")
		return &ReviewResult{
			GoalAchieved: false,
			Confidence:   0.5,
			Summary:      "Review parsing failed",
		}, nil
	}

	return &review, nil
}

// executeTool executes a single tool via StepManager and returns the result.
// It resolves the tool configuration from available_tools and creates a synthetic JobStep.
func (w *OrchestratorWorker) executeTool(
	ctx context.Context,
	planStep PlanStep,
	toolConfig map[string]interface{},
	jobDef models.JobDefinition,
	parentJobID string,
) PlanStepResult {
	result := PlanStepResult{
		StepID:  planStep.ID,
		Tool:    planStep.Tool,
		Success: false,
	}

	// Get worker type from tool config
	workerType, ok := toolConfig["worker"].(string)
	if !ok || workerType == "" {
		result.Error = fmt.Sprintf("tool '%s' has no worker type configured", planStep.Tool)
		return result
	}

	// Build step config from tool config and plan step params
	stepConfig := make(map[string]interface{})

	// Copy tool-specific config (like 'template' for job_template worker)
	for k, v := range toolConfig {
		if k != "name" && k != "description" && k != "worker" {
			stepConfig[k] = v
		}
	}

	// Merge plan step params (these override tool config)
	for k, v := range planStep.Params {
		stepConfig[k] = v
	}

	// Create synthetic JobStep
	syntheticStep := models.JobStep{
		Name:        fmt.Sprintf("orchestrated_%s", planStep.ID),
		Type:        models.WorkerType(workerType),
		Description: fmt.Sprintf("Orchestrated execution of %s", planStep.Tool),
		Config:      stepConfig,
		OnError:     models.ErrorStrategyContinue,
	}

	w.logger.Debug().
		Str("step_id", planStep.ID).
		Str("tool", planStep.Tool).
		Str("worker_type", workerType).
		Msg("Executing tool via StepManager")

	// Execute via StepManager
	_, err := w.stepManager.Execute(ctx, syntheticStep, jobDef, parentJobID, nil)
	if err != nil {
		result.Error = fmt.Sprintf("tool execution failed: %v", err)
		w.logger.Warn().
			Err(err).
			Str("step_id", planStep.ID).
			Str("tool", planStep.Tool).
			Msg("Tool execution failed")
		return result
	}

	result.Success = true
	result.Output = fmt.Sprintf("Successfully executed %s (worker: %s)", planStep.Tool, workerType)

	// Try to find and summarize output documents created by this tool
	// Workers typically tag their output with job-specific tags
	if w.searchService != nil {
		// Search for recent documents with tags matching the step name
		searchOpts := interfaces.SearchOptions{
			Limit: 5,
			// Note: We don't filter by tags here because we don't know what tags the worker used.
			// The worker output is already captured by the parent job's document storage.
		}

		// Search for documents created in the last few minutes with content from this execution
		docs, err := w.searchService.Search(ctx, syntheticStep.Name, searchOpts)
		if err == nil && len(docs) > 0 {
			var docSummaries []string
			for _, doc := range docs {
				summary := truncateString(doc.ContentMarkdown, 500)
				docSummaries = append(docSummaries, fmt.Sprintf("- %s: %s", doc.Title, summary))
			}
			if len(docSummaries) > 0 {
				result.Output = fmt.Sprintf("Executed %s (worker: %s). Output documents:\n%s",
					planStep.Tool, workerType, strings.Join(docSummaries, "\n"))
			}
		}
	}

	w.logger.Info().
		Str("step_id", planStep.ID).
		Str("tool", planStep.Tool).
		Bool("success", result.Success).
		Msg("Tool execution completed")

	return result
}

// buildOutputContent creates markdown content from orchestration results
func (w *OrchestratorWorker) buildOutputContent(goal string, plan *Plan, results []PlanStepResult, review *ReviewResult) string {
	var sb strings.Builder

	sb.WriteString("# Orchestration Results\n\n")

	// Goal section
	sb.WriteString("## Goal\n")
	sb.WriteString(goal)
	sb.WriteString("\n\n")

	// Plan summary
	if plan != nil {
		sb.WriteString("## Execution Plan\n")
		sb.WriteString(fmt.Sprintf("**Reasoning:** %s\n\n", plan.Reasoning))

		if len(plan.Steps) > 0 {
			sb.WriteString("### Steps\n")
			for i, step := range plan.Steps {
				sb.WriteString(fmt.Sprintf("%d. **%s** (tool: %s)\n", i+1, step.ID, step.Tool))
			}
			sb.WriteString("\n")
		}
	}

	// Execution results
	if len(results) > 0 {
		sb.WriteString("## Execution Results\n\n")
		for _, result := range results {
			status := "Success"
			if !result.Success {
				status = "Failed"
			}
			sb.WriteString(fmt.Sprintf("### %s (%s)\n", result.StepID, status))
			if result.Success {
				sb.WriteString(result.Output)
			} else {
				sb.WriteString(fmt.Sprintf("Error: %s", result.Error))
			}
			sb.WriteString("\n\n")
		}
	}

	// Review summary
	if review != nil {
		sb.WriteString("## Review Summary\n\n")
		goalStatus := "Not Achieved"
		if review.GoalAchieved {
			goalStatus = "Achieved"
		}
		sb.WriteString(fmt.Sprintf("- **Goal Status:** %s\n", goalStatus))
		sb.WriteString(fmt.Sprintf("- **Confidence:** %.0f%%\n", review.Confidence*100))
		sb.WriteString(fmt.Sprintf("- **Summary:** %s\n", review.Summary))

		if len(review.MissingData) > 0 {
			sb.WriteString(fmt.Sprintf("- **Missing Data:** %s\n", strings.Join(review.MissingData, ", ")))
		}
	}

	return sb.String()
}

// saveOutputDocument saves the orchestration execution log as a document.
// IMPORTANT: This document uses INTERNAL tags only (orchestrator-execution-log),
// NOT the output_tags from step config. This ensures that worker-produced
// documents (which have the actual content) are found by downstream steps
// like email, instead of this execution summary.
func (w *OrchestratorWorker) saveOutputDocument(ctx context.Context, stepID string, step models.JobStep, jobDef models.JobDefinition, content string) error {
	if content == "" {
		return nil // Nothing to save
	}

	now := time.Now()

	// Use INTERNAL tags only - NOT output_tags from step config
	// This prevents the orchestrator's execution summary from overshadowing
	// the actual content produced by workers (which use output_tags)
	tags := []string{"orchestrator-execution-log"}

	// Add job tags
	if len(jobDef.Tags) > 0 {
		tags = append(tags, jobDef.Tags...)
	}

	// Create title from step description or job name
	title := step.Description
	if title == "" {
		title = jobDef.Name
	}
	if title == "" {
		title = "Orchestration Output"
	}

	doc := &models.Document{
		ID:              "doc_" + uuid.New().String(),
		SourceType:      "orchestrator",
		SourceID:        stepID,
		Title:           title,
		ContentMarkdown: content,
		DetailLevel:     models.DetailLevelFull,
		Metadata: map[string]interface{}{
			"job_id":  jobDef.ID,
			"step_id": stepID,
		},
		Tags:       tags,
		CreatedAt:  now,
		UpdatedAt:  now,
		LastSynced: &now,
	}

	if err := w.documentStorage.SaveDocument(doc); err != nil {
		return fmt.Errorf("failed to save document: %w", err)
	}

	w.logger.Info().
		Str("doc_id", doc.ID).
		Strs("tags", tags).
		Int("content_len", len(content)).
		Msg("Saved orchestrator output document")

	return nil
}
