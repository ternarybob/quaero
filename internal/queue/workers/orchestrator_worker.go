// -----------------------------------------------------------------------
// OrchestratorWorker - AI-powered cognitive orchestration using LLM reasoning
// Receives a goal and available tools, dynamically plans and executes steps
// using a Planner-Executor-Reviewer loop.
// -----------------------------------------------------------------------

package workers

import (
	"context"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"github.com/google/uuid"
	"github.com/pelletier/go-toml/v2"
	"github.com/ternarybob/arbor"
	"github.com/ternarybob/quaero/internal/interfaces"
	"github.com/ternarybob/quaero/internal/models"
	"github.com/ternarybob/quaero/internal/queue"
	"github.com/ternarybob/quaero/internal/services/llm"
)

// Plan represents a dynamic execution plan generated by the LLM Planner
type Plan struct {
	Reasoning string     `json:"reasoning"`
	Steps     []PlanStep `json:"steps"`
	Error     bool       `json:"error,omitempty"` // True if planner could not create a valid plan
}

// PlanStep represents a single step in the execution plan
type PlanStep struct {
	ID        string                 `json:"id"`
	Tool      string                 `json:"tool"`
	Params    map[string]interface{} `json:"params"`
	DependsOn []string               `json:"depends_on,omitempty"`
}

// PlanStepResult holds the result of executing a plan step
type PlanStepResult struct {
	StepID  string
	Tool    string
	Success bool
	Output  string
	Error   string
}

// mutuallyExclusiveTags defines tag pairs that should NEVER appear together in filter_tags
// because they represent different document types (AND logic would find zero documents)
var mutuallyExclusiveTags = [][2]string{
	// ASX stock data pairs
	{"asx-stock-data", "asx-index"},
	{"asx-stock-data", "asx-announcement"},
	{"asx-stock-data", "asx-analyst-coverage"},
	{"asx-stock-data", "asx-historical-financials"},
	{"asx-stock-data", "web-search"},
	{"asx-stock-data", "macro-data"},
	{"asx-stock-data", "director-interest"},
	// ASX index pairs
	{"asx-index", "asx-announcement"},
	{"asx-index", "asx-analyst-coverage"},
	{"asx-index", "asx-historical-financials"},
	{"asx-index", "web-search"},
	{"asx-index", "macro-data"},
	{"asx-index", "director-interest"},
	// ASX announcement pairs
	{"asx-announcement", "asx-analyst-coverage"},
	{"asx-announcement", "asx-historical-financials"},
	{"asx-announcement", "web-search"},
	{"asx-announcement", "macro-data"},
	{"asx-announcement", "director-interest"},
	// ASX analyst coverage pairs
	{"asx-analyst-coverage", "asx-historical-financials"},
	{"asx-analyst-coverage", "web-search"},
	{"asx-analyst-coverage", "macro-data"},
	{"asx-analyst-coverage", "director-interest"},
	// ASX historical financials pairs
	{"asx-historical-financials", "web-search"},
	{"asx-historical-financials", "macro-data"},
	{"asx-historical-financials", "director-interest"},
	// Web search pairs
	{"web-search", "macro-data"},
	{"web-search", "director-interest"},
	// Macro data pairs
	{"macro-data", "director-interest"},
}

// validateFilterTags checks if filter_tags contain mutually exclusive tag pairs
// Returns an error describing the invalid combination if found
func validateFilterTags(filterTags []string) error {
	if len(filterTags) < 2 {
		return nil
	}

	tagSet := make(map[string]bool)
	for _, tag := range filterTags {
		tagSet[tag] = true
	}

	for _, pair := range mutuallyExclusiveTags {
		if tagSet[pair[0]] && tagSet[pair[1]] {
			return fmt.Errorf("invalid filter_tags: '%s' and '%s' are mutually exclusive (different document types, AND logic will find zero documents)", pair[0], pair[1])
		}
	}
	return nil
}

// validatePlanSteps validates all steps in a plan for common mistakes
func validatePlanSteps(plan *Plan) error {
	for _, step := range plan.Steps {
		// Only validate analyze_summary steps which use filter_tags
		if step.Tool != "analyze_summary" {
			continue
		}

		filterTagsRaw, ok := step.Params["filter_tags"]
		if !ok {
			continue
		}

		var filterTags []string
		switch v := filterTagsRaw.(type) {
		case []interface{}:
			for _, tag := range v {
				if tagStr, ok := tag.(string); ok {
					filterTags = append(filterTags, tagStr)
				}
			}
		case []string:
			filterTags = v
		}

		if err := validateFilterTags(filterTags); err != nil {
			return fmt.Errorf("step '%s': %w", step.ID, err)
		}
	}
	return nil
}

// plannerSystemPrompt is the system instruction for the Planner LLM
// CRITICAL: This prompt enforces FORCED TOOL USE - the AI must call tools and cannot fabricate data
const plannerSystemPrompt = `You are an intelligent orchestration planner. Your ONLY job is to decide which tools to call.

CRITICAL RULES - FORCED TOOL USE:
1. You have ZERO knowledge of stock prices, financial data, or any external information
2. You MUST call at least one tool to retrieve ANY data - you cannot answer from memory
3. Return ONLY tool calls - no explanatory text, no analysis, no fabricated data
4. If no tools can answer the query, you MUST return an error - NEVER fabricate data
5. Output ONLY valid JSON - no markdown code blocks, no explanations before or after

EXECUTION RULES:
1. Each step must use exactly one tool from the available_tools list
2. Steps can depend on other steps using the depends_on field
3. Use meaningful step IDs like "step_1_fetch_data", "step_2_analyze"
4. Params must match what the tool expects

DEPENDENCY ORDERING:
1. Data collection tools create documents tagged with specific types
2. Analysis tools (analyze_summary) require documents to exist FIRST
3. Analysis steps MUST have depends_on pointing to their data collection steps

TAG FILTERING - CRITICAL (READ CAREFULLY):
filter_tags uses AND logic - documents must have ALL specified tags to match.

Document tags by tool:
- fetch_stock_data: ["asx-stock-data", "<ticker>"] e.g. ["asx-stock-data", "gnp"]
- fetch_index_data: ["asx-index", "<code>", "benchmark"] e.g. ["asx-index", "xjo"]
- fetch_announcements: ["asx-announcement", "<ticker>"] e.g. ["asx-announcement", "gnp"]
- fetch_analyst_coverage: ["asx-analyst-coverage", "<ticker>"] e.g. ["asx-analyst-coverage", "gnp"]
- fetch_historical_financials: ["asx-historical-financials", "<ticker>"] e.g. ["asx-historical-financials", "gnp"]
- search_web: ["web-search"] ONLY (no ticker tag)

CORRECT filter_tags examples:
- Analyze GNP stock data: ["asx-stock-data", "gnp"]
- Analyze GNP announcements: ["asx-announcement", "gnp"]
- Analyze GNP analyst coverage: ["asx-analyst-coverage", "gnp"]
- Analyze GNP historical financials: ["asx-historical-financials", "gnp"]
- Analyze web search results: ["web-search"]

WRONG filter_tags (will find ZERO documents):
- ["asx-stock-data", "asx-index"] - NEVER combine stock data and index tags!
- ["asx-stock-data", "asx-announcement"] - no doc has both type tags
- ["asx-stock-data", "web-search", "gnp"] - no doc has all these
- ["gnp", "sks"] - no doc is tagged with multiple tickers

MUTUALLY EXCLUSIVE TAGS (never combine these):
- "asx-stock-data" and "asx-index" - different document types
- "asx-stock-data" and "asx-announcement" - different document types
- "asx-stock-data" and "asx-analyst-coverage" - different document types
- "asx-stock-data" and "asx-historical-financials" - different document types
- "asx-stock-data" and "web-search" - different document types
- "asx-index" and "asx-announcement" - different document types
- Any other document type combinations (each tag represents a separate document type)

For comprehensive analysis across data types, create SEPARATE analyze_summary calls:
1. One for stock data: filter_tags: ["asx-stock-data", "gnp"]
2. One for announcements: filter_tags: ["asx-announcement", "gnp"]
3. One for analyst coverage: filter_tags: ["asx-analyst-coverage", "gnp"]
4. One for historical financials: filter_tags: ["asx-historical-financials", "gnp"]
5. One for web search: filter_tags: ["web-search"]
6. Final synthesis step that depends on all analysis steps

STOCKS vs BENCHMARKS - CRITICAL DISTINCTION:
The CONTEXT section may contain two types of data:

1. "STOCKS TO ANALYZE" (from variables):
   - These are the PRIMARY TARGETS - you MUST create tool calls for EACH stock
   - For each stock ticker, call: fetch_stock_data, fetch_announcements, fetch_analyst_coverage, fetch_historical_financials, search_web
   - Example: If stocks = [GNP, SKS, WES], you need 15 data collection steps (5 tools Ã— 3 stocks)
   - Then create analysis steps for each stock's data

2. "BENCHMARK INDICES" (from benchmarks):
   - These are SECONDARY reference data for comparison only
   - Call fetch_index_data for each benchmark code (e.g., XJO)
   - Do NOT call fetch_stock_data or fetch_announcements for benchmarks

COMMON MISTAKE TO AVOID:
- WRONG: Only analyze the benchmark index (XJO) and ignore the stocks in variables
- CORRECT: Analyze ALL stocks from the variables list, use benchmark for comparison only
- If you see 7 stocks in STOCKS TO ANALYZE, your plan must include steps for all 7 stocks

OUTPUT FORMAT (JSON only):
{
  "reasoning": "Brief explanation of which tools are needed and why",
  "steps": [
    {
      "id": "step_1_fetch_gnp_data",
      "tool": "fetch_stock_data",
      "params": {"asx_code": "GNP"},
      "depends_on": []
    },
    {
      "id": "step_2_fetch_gnp_ann",
      "tool": "fetch_announcements",
      "params": {"asx_code": "GNP"},
      "depends_on": []
    },
    {
      "id": "step_3_analyze_gnp_data",
      "tool": "analyze_summary",
      "params": {"prompt": "Analyze GNP stock metrics", "filter_tags": ["asx-stock-data", "gnp"]},
      "depends_on": ["step_1_fetch_gnp_data"]
    },
    {
      "id": "step_4_analyze_gnp_ann",
      "tool": "analyze_summary",
      "params": {"prompt": "Analyze GNP announcements", "filter_tags": ["asx-announcement", "gnp"]},
      "depends_on": ["step_2_fetch_gnp_ann"]
    },
    {
      "id": "step_5_final",
      "tool": "analyze_summary",
      "params": {"prompt": "Create final recommendation", "filter_tags": ["asx-stock-data", "gnp"]},
      "depends_on": ["step_3_analyze_gnp_data", "step_4_analyze_gnp_ann"]
    }
  ]
}

If the goal CANNOT be achieved with available tools, return:
{
  "reasoning": "ERROR: Cannot achieve goal because [specific reason].",
  "steps": [],
  "error": true
}

NEVER return an empty steps array unless it's truly impossible to proceed with available tools.`

// reviewerSystemPrompt is the system instruction for the Reviewer LLM
const reviewerSystemPrompt = `You are a quality reviewer for orchestration results. Analyze the execution results against the original goal.

IMPORTANT RULES:
1. Output ONLY valid JSON - no markdown code blocks, no explanations
2. Check if the goal was achieved based on the results
3. Identify any missing data or failures
4. If recovery is needed, suggest specific actions

JUDGMENT GUIDELINES - Be pragmatic, not pedantic:
1. Focus on SUBSTANCE over FORM: If the requested analysis/content was produced, the goal is achieved
2. Single-item edge cases: A goal asking for "all items" is achieved if all items in the input were processed, even if there's only one
3. "Summary table" with one item: A single-item analysis is still valid - format requirements are secondary to content
4. Successful tool execution with valid output = goal achieved, even if formatting differs from ideal
5. The goal is about WHAT was accomplished, not HOW it was formatted

OUTPUT FORMAT (JSON only):
{
  "goal_achieved": true/false,
  "confidence": 0.0-1.0,
  "summary": "Brief summary of results",
  "missing_data": ["list of missing items"],
  "recovery_actions": [
    {"tool": "tool_name", "params": {"key": "value"}, "reason": "why needed"}
  ]
}`

// ThinkingLevel represents the depth of LLM reasoning for orchestration
type ThinkingLevel string

const (
	ThinkingLevelMinimal ThinkingLevel = "MINIMAL" // Quick planning, minimal reasoning
	ThinkingLevelLow     ThinkingLevel = "LOW"     // Light reasoning, fast execution
	ThinkingLevelMedium  ThinkingLevel = "MEDIUM"  // Balanced reasoning (default)
	ThinkingLevelHigh    ThinkingLevel = "HIGH"    // Deep reasoning, thorough analysis
)

// OrchestratorWorker implements AI-powered cognitive orchestration.
// It uses LLM reasoning to dynamically plan and execute steps based on a goal.
// This is the "thinking" component that makes decisions about what to do.
//
// Configuration (step.config):
//   - goal (string, required): Natural language description of the desired outcome
//   - context_files ([]string, optional): Files to read for context
//   - available_tools ([]map, optional): Workers exposed as callable tools
//   - thinking_level (string, optional): MINIMAL, LOW, MEDIUM, HIGH (default: MEDIUM)
//   - output_schema (string, optional): Path to validation schema
//   - model_preference (string, optional): Model selection: auto, flash, pro
type OrchestratorWorker struct {
	documentStorage interfaces.DocumentStorage
	searchService   interfaces.SearchService
	kvStorage       interfaces.KeyValueStorage
	eventService    interfaces.EventService
	logger          arbor.ILogger
	jobMgr          *queue.Manager
	providerFactory *llm.ProviderFactory
	stepManager     interfaces.StepManager
	templatesDir    string // Directory containing goal templates
}

// Compile-time assertion: OrchestratorWorker implements DefinitionWorker interface
var _ interfaces.DefinitionWorker = (*OrchestratorWorker)(nil)

// NewOrchestratorWorker creates a new orchestrator worker
func NewOrchestratorWorker(
	documentStorage interfaces.DocumentStorage,
	searchService interfaces.SearchService,
	kvStorage interfaces.KeyValueStorage,
	eventService interfaces.EventService,
	logger arbor.ILogger,
	jobMgr *queue.Manager,
	providerFactory *llm.ProviderFactory,
	templatesDir string,
) *OrchestratorWorker {
	return &OrchestratorWorker{
		documentStorage: documentStorage,
		searchService:   searchService,
		kvStorage:       kvStorage,
		eventService:    eventService,
		logger:          logger,
		jobMgr:          jobMgr,
		providerFactory: providerFactory,
		templatesDir:    templatesDir,
	}
}

// SetStepManager sets the step manager for executing tool calls.
// This is set after construction to avoid circular dependency during initialization.
func (w *OrchestratorWorker) SetStepManager(sm interfaces.StepManager) {
	w.stepManager = sm
}

// GetType returns WorkerTypeOrchestrator for the DefinitionWorker interface
func (w *OrchestratorWorker) GetType() models.WorkerType {
	return models.WorkerTypeOrchestrator
}

// GoalTemplateConfig holds configuration loaded from a goal template file
type GoalTemplateConfig struct {
	Goal            string
	ThinkingLevel   string
	ModelPreference string
	OutputTags      []string
	AvailableTools  []map[string]interface{}
	OutputSchema    map[string]interface{} // JSON schema for structured LLM output
	OutputSchemaRef string                 // Reference to external schema file (e.g., "stock-report.schema.json")
}

// loadSchemaFromFile loads a JSON schema from the schemas directory.
// The schemas directory is expected to be a sibling of the templates directory (../schemas/).
// schemaRef is the filename (e.g., "stock-report.schema.json")
// This function resolves $ref references by loading and inlining referenced schemas.
func (w *OrchestratorWorker) loadSchemaFromFile(schemaRef string) (map[string]interface{}, error) {
	if schemaRef == "" {
		return nil, nil
	}

	// Schemas are in ../schemas/ relative to templates directory
	schemasDir := filepath.Join(filepath.Dir(w.templatesDir), "schemas")
	schemaPath := filepath.Join(schemasDir, schemaRef)

	// Check if file exists
	if _, err := os.Stat(schemaPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("schema file not found: %s", schemaPath)
	}

	// Read schema file
	schemaContent, err := os.ReadFile(schemaPath)
	if err != nil {
		return nil, fmt.Errorf("failed to read schema file: %w", err)
	}

	// Parse JSON schema
	var schema map[string]interface{}
	if err := json.Unmarshal(schemaContent, &schema); err != nil {
		return nil, fmt.Errorf("failed to parse schema JSON: %w", err)
	}

	// Resolve $ref references by loading and inlining referenced schemas
	// This is required because Gemini's ResponseSchema doesn't support $ref
	visited := make(map[string]bool)
	visited[schemaRef] = true // Mark current schema as visited to prevent self-reference
	if err := w.resolveSchemaRefs(schema, schemasDir, visited); err != nil {
		w.logger.Warn().
			Err(err).
			Str("schema_ref", schemaRef).
			Msg("Failed to fully resolve $ref in schema, continuing with partial resolution")
		// Continue with partial resolution rather than failing
	}

	w.logger.Info().
		Str("schema_ref", schemaRef).
		Str("schema_path", schemaPath).
		Int("refs_resolved", len(visited)-1).
		Msg("Loaded external JSON schema with $ref resolution")

	return schema, nil
}

// resolveSchemaRefs recursively resolves $ref references in a JSON schema.
// It replaces $ref objects with the content of the referenced schema file.
// schemasDir is the directory containing schema files.
// visited tracks already-resolved refs to prevent cycles.
func (w *OrchestratorWorker) resolveSchemaRefs(schema map[string]interface{}, schemasDir string, visited map[string]bool) error {
	for key, value := range schema {
		switch v := value.(type) {
		case map[string]interface{}:
			// Check for $ref
			if ref, ok := v["$ref"].(string); ok {
				// Security: only allow same-directory refs (no path traversal)
				if strings.Contains(ref, "/") || strings.Contains(ref, "\\") || strings.HasPrefix(ref, ".") {
					w.logger.Warn().
						Str("ref", ref).
						Msg("Skipping $ref with path components for security")
					continue
				}

				// Prevent cycles
				if visited[ref] {
					w.logger.Debug().
						Str("ref", ref).
						Msg("Skipping already-visited $ref to prevent cycle")
					continue
				}
				visited[ref] = true

				// Load referenced schema
				refPath := filepath.Join(schemasDir, ref)
				refData, err := os.ReadFile(refPath)
				if err != nil {
					return fmt.Errorf("failed to load $ref '%s': %w", ref, err)
				}

				var refSchema map[string]interface{}
				if err := json.Unmarshal(refData, &refSchema); err != nil {
					return fmt.Errorf("failed to parse $ref '%s': %w", ref, err)
				}

				// Recursively resolve refs in the referenced schema
				if err := w.resolveSchemaRefs(refSchema, schemasDir, visited); err != nil {
					return err
				}

				// Replace the $ref object with the resolved schema content
				schema[key] = refSchema
				w.logger.Debug().
					Str("ref", ref).
					Str("key", key).
					Msg("Resolved $ref and inlined schema")
			} else {
				// Recursively resolve refs in nested objects
				if err := w.resolveSchemaRefs(v, schemasDir, visited); err != nil {
					return err
				}
			}
		case []interface{}:
			// Handle arrays (e.g., allOf, anyOf, oneOf)
			for i, item := range v {
				if itemMap, ok := item.(map[string]interface{}); ok {
					if err := w.resolveSchemaRefs(itemMap, schemasDir, visited); err != nil {
						return err
					}
					v[i] = itemMap
				}
			}
		}
	}
	return nil
}

// loadGoalTemplate loads a goal template from the templates directory.
// Template files are expected to have a [template] section containing:
// - goal: The natural language goal for the orchestrator
// - thinking_level: LLM reasoning depth (MINIMAL, LOW, MEDIUM, HIGH)
// - model_preference: Model selection preference (auto, flash, pro, etc.)
// - output_tags: Tags to apply to output documents
// - available_tools: Array of tool definitions for the orchestrator
// - output_schema_ref: Reference to external JSON schema file (e.g., "stock-report.schema.json")
func (w *OrchestratorWorker) loadGoalTemplate(templateName string) (*GoalTemplateConfig, error) {
	if w.templatesDir == "" {
		return nil, fmt.Errorf("templates directory not configured")
	}

	// Build template file path - support both TOML and JSON templates
	var templateFile string
	var isJSON bool

	// Try JSON first, then TOML
	jsonFile := filepath.Join(w.templatesDir, templateName+".json")
	tomlFile := filepath.Join(w.templatesDir, templateName+".toml")

	if _, err := os.Stat(jsonFile); err == nil {
		templateFile = jsonFile
		isJSON = true
	} else if _, err := os.Stat(tomlFile); err == nil {
		templateFile = tomlFile
		isJSON = false
	} else {
		return nil, fmt.Errorf("goal template file not found: %s (tried .json and .toml)", templateName)
	}

	// Read template content
	templateContent, err := os.ReadFile(templateFile)
	if err != nil {
		return nil, fmt.Errorf("failed to read goal template file: %w", err)
	}

	var config *GoalTemplateConfig

	if isJSON {
		// Parse JSON template
		config, err = w.parseJSONTemplate(templateContent)
		if err != nil {
			return nil, fmt.Errorf("failed to parse JSON template: %w", err)
		}
	} else {
		// Parse TOML template (legacy format)
		config, err = w.parseTOMLTemplate(templateContent)
		if err != nil {
			return nil, fmt.Errorf("failed to parse TOML template: %w", err)
		}
	}

	// If output_schema_ref is specified, load the external schema
	if config.OutputSchemaRef != "" && len(config.OutputSchema) == 0 {
		schema, err := w.loadSchemaFromFile(config.OutputSchemaRef)
		if err != nil {
			return nil, fmt.Errorf("failed to load output schema '%s': %w", config.OutputSchemaRef, err)
		}
		config.OutputSchema = schema
	}

	if config.Goal == "" {
		return nil, fmt.Errorf("goal template '%s' does not contain a goal", templateName)
	}

	hasSchema := config.OutputSchema != nil && len(config.OutputSchema) > 0
	w.logger.Info().
		Str("template", templateName).
		Str("format", map[bool]string{true: "json", false: "toml"}[isJSON]).
		Str("thinking_level", config.ThinkingLevel).
		Str("model_preference", config.ModelPreference).
		Int("output_tags", len(config.OutputTags)).
		Int("available_tools", len(config.AvailableTools)).
		Bool("has_output_schema", hasSchema).
		Str("output_schema_ref", config.OutputSchemaRef).
		Msg("Loaded goal template")

	return config, nil
}

// parseTOMLTemplate parses a TOML-format goal template
func (w *OrchestratorWorker) parseTOMLTemplate(content []byte) (*GoalTemplateConfig, error) {
	type GoalTemplateFile struct {
		Template struct {
			Goal            string                   `toml:"goal"`
			ThinkingLevel   string                   `toml:"thinking_level"`
			ModelPreference string                   `toml:"model_preference"`
			OutputTags      []string                 `toml:"output_tags"`
			AvailableTools  []map[string]interface{} `toml:"available_tools"`
			OutputSchema    map[string]interface{}   `toml:"output_schema"`     // Inline JSON schema (legacy)
			OutputSchemaRef string                   `toml:"output_schema_ref"` // Reference to external schema file
		} `toml:"template"`
	}

	var templateFile GoalTemplateFile
	if err := toml.Unmarshal(content, &templateFile); err != nil {
		return nil, err
	}

	return &GoalTemplateConfig{
		Goal:            templateFile.Template.Goal,
		ThinkingLevel:   templateFile.Template.ThinkingLevel,
		ModelPreference: templateFile.Template.ModelPreference,
		OutputTags:      templateFile.Template.OutputTags,
		AvailableTools:  templateFile.Template.AvailableTools,
		OutputSchema:    templateFile.Template.OutputSchema,
		OutputSchemaRef: templateFile.Template.OutputSchemaRef,
	}, nil
}

// parseJSONTemplate parses a JSON-format goal template
func (w *OrchestratorWorker) parseJSONTemplate(content []byte) (*GoalTemplateConfig, error) {
	type JSONTemplateFile struct {
		ID          string `json:"id"`
		Name        string `json:"name"`
		Type        string `json:"type"`
		Description string `json:"description"`
		Template    struct {
			Goal            string                   `json:"goal"`
			ThinkingLevel   string                   `json:"thinking_level"`
			ModelPreference string                   `json:"model_preference"`
			OutputTags      []string                 `json:"output_tags"`
			AvailableTools  []map[string]interface{} `json:"available_tools"`
			OutputSchemaRef string                   `json:"output_schema_ref"` // Reference to external schema file
		} `json:"template"`
	}

	var templateFile JSONTemplateFile
	if err := json.Unmarshal(content, &templateFile); err != nil {
		return nil, err
	}

	return &GoalTemplateConfig{
		Goal:            templateFile.Template.Goal,
		ThinkingLevel:   templateFile.Template.ThinkingLevel,
		ModelPreference: templateFile.Template.ModelPreference,
		OutputTags:      templateFile.Template.OutputTags,
		AvailableTools:  templateFile.Template.AvailableTools,
		OutputSchemaRef: templateFile.Template.OutputSchemaRef,
	}, nil
}

// ValidateConfig validates step configuration before execution.
// Checks for required fields and valid values.
// Accepts either 'goal' (inline) or 'goal_template' (reference to template file).
func (w *OrchestratorWorker) ValidateConfig(step models.JobStep) error {
	config := step.Config
	if config == nil {
		return fmt.Errorf("step config is required for orchestrator")
	}

	// Validate goal: either 'goal' or 'goal_template' is required
	goal, hasGoal := config["goal"].(string)
	goalTemplate, hasGoalTemplate := config["goal_template"].(string)

	if hasGoal && strings.TrimSpace(goal) != "" {
		// Inline goal - valid
	} else if hasGoalTemplate && strings.TrimSpace(goalTemplate) != "" {
		// Goal template reference - valid (will be loaded at Init time)
	} else {
		return fmt.Errorf("either 'goal' or 'goal_template' is required in orchestrator step config")
	}

	// Validate thinking_level if provided
	if level, ok := config["thinking_level"].(string); ok {
		levelUpper := strings.ToUpper(level)
		switch ThinkingLevel(levelUpper) {
		case ThinkingLevelMinimal, ThinkingLevelLow, ThinkingLevelMedium, ThinkingLevelHigh:
			// Valid
		default:
			return fmt.Errorf("invalid thinking_level '%s': must be MINIMAL, LOW, MEDIUM, or HIGH", level)
		}
	}

	// Validate available_tools format if provided
	if tools, ok := config["available_tools"]; ok {
		switch t := tools.(type) {
		case []interface{}:
			// Valid: array of tool definitions
			for i, tool := range t {
				if toolMap, ok := tool.(map[string]interface{}); ok {
					if _, hasName := toolMap["name"]; !hasName {
						return fmt.Errorf("available_tools[%d] must have a 'name' field", i)
					}
				} else {
					return fmt.Errorf("available_tools[%d] must be a map with 'name' and optional 'description'", i)
				}
			}
		case []map[string]interface{}:
			// Valid: typed array
		default:
			return fmt.Errorf("available_tools must be an array of tool definitions")
		}
	}

	return nil
}

// Init performs the initialization/setup phase for an orchestrator step.
// This is where we:
//   - Extract and validate configuration (goal, context, tools)
//   - Load goal_template if specified (template provides goal, tools, thinking_level, etc.)
//   - Prepare the context for LLM planning
//   - Return metadata for CreateJobs
//
// The Init phase does NOT execute any planning - it only validates and prepares.
//
// Configuration priority:
//   - goal_template: If specified, loads goal/tools/thinking_level/output_tags from template
//   - Step config can override template values (e.g., step-level thinking_level wins)
//   - Variables and benchmarks come from job definition [config] section (user data)
func (w *OrchestratorWorker) Init(ctx context.Context, step models.JobStep, jobDef models.JobDefinition) (*interfaces.WorkerInitResult, error) {
	config := step.Config
	if config == nil {
		return nil, fmt.Errorf("step config is required for orchestrator")
	}

	var goal string
	var availableTools []map[string]interface{}
	var outputTags []string
	var outputSchema map[string]interface{} // JSON schema for structured LLM output
	thinkingLevel := ThinkingLevelMedium
	modelPreference := "auto"

	// Check for goal_template first
	if goalTemplate, ok := config["goal_template"].(string); ok && strings.TrimSpace(goalTemplate) != "" {
		// Load goal from template
		templateConfig, err := w.loadGoalTemplate(goalTemplate)
		if err != nil {
			return nil, fmt.Errorf("failed to load goal_template '%s': %w", goalTemplate, err)
		}

		// Apply template values as defaults
		goal = templateConfig.Goal
		availableTools = templateConfig.AvailableTools
		outputTags = templateConfig.OutputTags
		outputSchema = templateConfig.OutputSchema

		if templateConfig.ThinkingLevel != "" {
			thinkingLevel = ThinkingLevel(strings.ToUpper(templateConfig.ThinkingLevel))
		}
		if templateConfig.ModelPreference != "" {
			modelPreference = templateConfig.ModelPreference
		}

		hasSchema := outputSchema != nil && len(outputSchema) > 0
		w.logger.Info().
			Str("goal_template", goalTemplate).
			Int("tools_from_template", len(availableTools)).
			Int("output_tags", len(outputTags)).
			Bool("has_output_schema", hasSchema).
			Msg("Loaded goal template")
	}

	// Step config can override template values
	if inlineGoal, ok := config["goal"].(string); ok && strings.TrimSpace(inlineGoal) != "" {
		goal = inlineGoal // Step-level goal overrides template
	}
	if goal == "" {
		return nil, fmt.Errorf("either 'goal' or 'goal_template' is required in orchestrator step config")
	}

	// Extract thinking_level from step config (overrides template)
	if level, ok := config["thinking_level"].(string); ok {
		thinkingLevel = ThinkingLevel(strings.ToUpper(level))
	}

	// Extract model_preference from step config (overrides template)
	if pref, ok := config["model_preference"].(string); ok {
		modelPreference = pref
	}

	// Extract output_tags from step config (overrides template)
	if tags, ok := config["output_tags"].([]interface{}); ok {
		outputTags = nil // Reset to step-level tags
		for _, t := range tags {
			if s, ok := t.(string); ok {
				outputTags = append(outputTags, s)
			}
		}
	} else if tags, ok := config["output_tags"].([]string); ok {
		outputTags = tags
	}

	// Extract available_tools from step config (overrides template)
	if tools, ok := config["available_tools"].([]interface{}); ok {
		availableTools = nil // Reset to step-level tools
		for _, t := range tools {
			if toolMap, ok := t.(map[string]interface{}); ok {
				availableTools = append(availableTools, toolMap)
			}
		}
	} else if tools, ok := config["available_tools"].([]map[string]interface{}); ok {
		availableTools = tools
	}

	// Extract variables from job definition config (the standard pattern for user data)
	// Variables are defined in the [config] section of the job definition TOML
	var variables []map[string]interface{}
	if jobConfig := jobDef.Config; jobConfig != nil {
		if vars, ok := jobConfig["variables"].([]interface{}); ok {
			for _, v := range vars {
				if varMap, ok := v.(map[string]interface{}); ok {
					variables = append(variables, varMap)
				}
			}
		} else if vars, ok := jobConfig["variables"].([]map[string]interface{}); ok {
			variables = vars
		}
	}

	// Also extract benchmarks if present (for portfolio jobs)
	var benchmarks []map[string]interface{}
	if jobConfig := jobDef.Config; jobConfig != nil {
		if b, ok := jobConfig["benchmarks"].([]interface{}); ok {
			for _, v := range b {
				if bMap, ok := v.(map[string]interface{}); ok {
					benchmarks = append(benchmarks, bMap)
				}
			}
		} else if b, ok := jobConfig["benchmarks"].([]map[string]interface{}); ok {
			benchmarks = b
		}
	}

	w.logger.Info().
		Str("phase", "init").
		Str("step_name", step.Name).
		Str("goal", truncateString(goal, 100)).
		Str("thinking_level", string(thinkingLevel)).
		Int("variables", len(variables)).
		Int("benchmarks", len(benchmarks)).
		Int("available_tools", len(availableTools)).
		Int("output_tags", len(outputTags)).
		Str("model_preference", modelPreference).
		Msg("Orchestrator worker initialized")

	// Create a single work item representing the orchestration task
	workItems := []interfaces.WorkItem{
		{
			ID:   "orchestration",
			Name: fmt.Sprintf("Orchestrate: %s", truncateString(goal, 50)),
			Type: "orchestrator",
			Config: map[string]interface{}{
				"goal": goal,
			},
		},
	}

	return &interfaces.WorkerInitResult{
		WorkItems:            workItems,
		TotalCount:           1,
		Strategy:             interfaces.ProcessingStrategyInline, // Synchronous execution for now
		SuggestedConcurrency: 1,
		Metadata: map[string]interface{}{
			"goal":             goal,
			"thinking_level":   string(thinkingLevel),
			"variables":        variables,
			"benchmarks":       benchmarks,
			"available_tools":  availableTools,
			"output_tags":      outputTags,
			"model_preference": modelPreference,
			"output_schema":    outputSchema, // JSON schema for structured LLM output
		},
	}, nil
}

// CreateJobs executes the orchestration logic using the Planner-Executor-Reviewer loop.
// 1. PLANNER: Uses LLM to create an execution plan based on goal and context
// 2. EXECUTOR: Executes plan steps using available tools (simulated for now)
// 3. REVIEWER: Verifies results and triggers recovery if needed
func (w *OrchestratorWorker) CreateJobs(ctx context.Context, step models.JobStep, jobDef models.JobDefinition, stepID string, initResult *interfaces.WorkerInitResult) (string, error) {
	// Call Init if not provided
	if initResult == nil {
		var err error
		initResult, err = w.Init(ctx, step, jobDef)
		if err != nil {
			return "", fmt.Errorf("failed to initialize orchestrator worker: %w", err)
		}
	}

	// Extract metadata from init result
	goal, _ := initResult.Metadata["goal"].(string)
	thinkingLevel, _ := initResult.Metadata["thinking_level"].(string)
	availableTools, _ := initResult.Metadata["available_tools"].([]map[string]interface{})
	variables, _ := initResult.Metadata["variables"].([]map[string]interface{})
	benchmarks, _ := initResult.Metadata["benchmarks"].([]map[string]interface{})
	modelPreference, _ := initResult.Metadata["model_preference"].(string)

	w.logger.Info().
		Str("phase", "run").
		Str("step_name", step.Name).
		Str("step_id", stepID).
		Str("goal", goal).
		Str("thinking_level", thinkingLevel).
		Int("available_tools", len(availableTools)).
		Int("variables", len(variables)).
		Int("benchmarks", len(benchmarks)).
		Msg("Starting orchestration")

	// Log step start for UI
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Orchestrator starting: goal='%s'", truncateString(goal, 100)))

		if len(availableTools) > 0 {
			toolNames := make([]string, 0, len(availableTools))
			for _, tool := range availableTools {
				if name, ok := tool["name"].(string); ok {
					toolNames = append(toolNames, name)
				}
			}
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("Available tools: %s", strings.Join(toolNames, ", ")))
		}
	}

	// =========================================================================
	// PHASE 1: PLANNER - Read variables and generate execution plan
	// =========================================================================
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Phase 1: PLANNER - Reading variables and generating plan...")
	}

	// Format variables as context for LLM
	contextContent := w.formatVariablesAsContext(variables, benchmarks)

	if len(variables) > 0 && w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Loaded %d variables, %d benchmarks", len(variables), len(benchmarks)))
	}

	// Generate execution plan using LLM
	plan, err := w.generatePlan(ctx, goal, contextContent, availableTools, thinkingLevel, modelPreference, stepID)
	if err != nil {
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "error", fmt.Sprintf("Planning failed: %v", err))
		}
		return "", fmt.Errorf("planning phase failed: %w", err)
	}

	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Plan generated: %s", truncateString(plan.Reasoning, 200)))
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Plan has %d steps", len(plan.Steps)))
	}

	// Log each planned step
	for i, planStep := range plan.Steps {
		if w.jobMgr != nil {
			paramsJSON, _ := json.Marshal(planStep.Params)
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("   Step %d: %s (tool: %s) params: %s", i+1, planStep.ID, planStep.Tool, string(paramsJSON)))
		}
	}

	// =========================================================================
	// PHASE 2: EXECUTOR - Create tool execution jobs as queue citizens
	// =========================================================================
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Phase 2: EXECUTOR - Creating tool execution jobs...")
	}

	// Build tool lookup map for quick access
	toolLookup := make(map[string]map[string]interface{})
	for _, tool := range availableTools {
		if name, ok := tool["name"].(string); ok {
			toolLookup[name] = tool
		}
	}

	// Create tool execution jobs in dependency order (waves)
	// Steps with no dependencies run first, then steps that depend on them, etc.
	// This ensures data collection tools complete before analysis tools that need their output
	var allResults []PlanStepResult
	toolJobMap := make(map[string]PlanStep) // jobID -> planStep for result collection
	completedSteps := make(map[string]bool) // track completed plan step IDs
	stepToJobID := make(map[string]string)  // plan step ID -> job ID

	// Build step lookup for dependency resolution
	stepLookup := make(map[string]PlanStep)
	for _, ps := range plan.Steps {
		stepLookup[ps.ID] = ps
	}

	// Identify terminal steps (steps that no other step depends on)
	// These will get the output_tags from the orchestrator config
	terminalSteps := make(map[string]bool)
	for _, ps := range plan.Steps {
		terminalSteps[ps.ID] = true // Assume all are terminal initially
	}
	for _, ps := range plan.Steps {
		for _, depID := range ps.DependsOn {
			terminalSteps[depID] = false // Not terminal if another step depends on it
		}
	}

	// Extract output_tags from initResult metadata (merged from template and step config)
	var outputTags []interface{}
	if tags, ok := initResult.Metadata["output_tags"].([]string); ok {
		for _, t := range tags {
			outputTags = append(outputTags, t)
		}
	} else if tags, ok := initResult.Metadata["output_tags"].([]interface{}); ok {
		outputTags = tags
	}

	// Extract output_schema from initResult metadata for structured JSON output
	var outputSchema map[string]interface{}
	if schema, ok := initResult.Metadata["output_schema"].(map[string]interface{}); ok && len(schema) > 0 {
		outputSchema = schema
	}

	// Execute in waves until all steps are done
	maxWaves := 10 // Safety limit
	for wave := 0; wave < maxWaves; wave++ {
		// Find steps that can run in this wave (all dependencies satisfied)
		var waveSteps []PlanStep
		for _, planStep := range plan.Steps {
			// Skip if already completed
			if completedSteps[planStep.ID] {
				continue
			}

			// Check if all dependencies are satisfied
			depsSatisfied := true
			for _, depID := range planStep.DependsOn {
				if !completedSteps[depID] {
					depsSatisfied = false
					break
				}
			}

			if depsSatisfied {
				waveSteps = append(waveSteps, planStep)
			}
		}

		// If no steps can run, we're either done or have a cycle
		if len(waveSteps) == 0 {
			break
		}

		if w.jobMgr != nil {
			stepNames := make([]string, len(waveSteps))
			for i, s := range waveSteps {
				stepNames[i] = s.Tool
			}
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("Wave %d: executing %d tools (%s)", wave+1, len(waveSteps), strings.Join(stepNames, ", ")))
		}

		// Create jobs for this wave
		var waveJobIDs []string
		for _, planStep := range waveSteps {
			// Find the tool configuration
			toolConfig, toolFound := toolLookup[planStep.Tool]
			if !toolFound {
				errMsg := fmt.Sprintf("tool '%s' not found in available_tools - check job definition", planStep.Tool)
				if w.jobMgr != nil {
					w.jobMgr.AddJobLog(ctx, stepID, "error", errMsg)
				}
				return "", fmt.Errorf("tool '%s' not found in available_tools - check job definition", planStep.Tool)
			}

			// Get worker type from tool config
			workerType, _ := toolConfig["worker"].(string)
			if workerType == "" {
				errMsg := fmt.Sprintf("tool '%s' has no worker type configured", planStep.Tool)
				if w.jobMgr != nil {
					w.jobMgr.AddJobLog(ctx, stepID, "error", errMsg)
				}
				return "", fmt.Errorf("tool '%s' has no worker type configured", planStep.Tool)
			}

			// Build job payload with tool config and plan step params
			jobPayload := map[string]interface{}{
				"plan_step_id":  planStep.ID,
				"tool_name":     planStep.Tool,
				"worker_type":   workerType,
				"params":        planStep.Params,
				"tool_config":   toolConfig,
				"job_def_id":    jobDef.ID,
				"manager_id":    stepID, // Link to orchestrator step
				"step_name":     step.Name,
				"original_goal": goal,
			}

			// Add output_tags ONLY to terminal analyze_summary steps
			// This ensures only the final analysis document (not raw data fetches) gets tagged for email
			// Data fetching tools (fetch_stock_data, fetch_index_data, etc.) should NOT get output_tags
			// even if they are terminal steps, as they produce raw data, not the final recommendation
			if terminalSteps[planStep.ID] && planStep.Tool == "analyze_summary" {
				if len(outputTags) > 0 {
					jobPayload["output_tags"] = outputTags
					tagsJSON, _ := json.Marshal(outputTags)
					w.logger.Debug().
						Str("step_id", planStep.ID).
						Str("output_tags", string(tagsJSON)).
						Msg("Added output_tags to terminal analyze_summary step")
				}

				// Pass required_tickers and benchmark_codes for output validation
				// This enables the summary worker to validate that all stocks are present
				// and benchmarks aren't treated as primary analysis targets
				requiredTickers := extractTickers(variables)
				benchmarkCodesList := extractBenchmarkCodes(benchmarks)

				if len(requiredTickers) > 0 {
					jobPayload["required_tickers"] = requiredTickers
					w.logger.Debug().
						Str("step_id", planStep.ID).
						Strs("required_tickers", requiredTickers).
						Msg("Added required_tickers to terminal analyze_summary step for validation")
				}

				if len(benchmarkCodesList) > 0 {
					jobPayload["benchmark_codes"] = benchmarkCodesList
					w.logger.Debug().
						Str("step_id", planStep.ID).
						Strs("benchmark_codes", benchmarkCodesList).
						Msg("Added benchmark_codes to terminal analyze_summary step for validation")
				}

				// Pass output_schema for structured JSON output
				// When provided, the LLM MUST return JSON matching this schema
				if outputSchema != nil && len(outputSchema) > 0 {
					jobPayload["output_schema"] = outputSchema
					w.logger.Debug().
						Str("step_id", planStep.ID).
						Msg("Added output_schema to terminal analyze_summary step for structured output")
				}
			}

			// Create tool execution job as queue citizen
			toolJobID, err := w.jobMgr.CreateChildJob(ctx, stepID, string(models.JobTypeToolExecution), "execution", jobPayload)
			if err != nil {
				w.logger.Error().Err(err).
					Str("tool", planStep.Tool).
					Str("step_id", planStep.ID).
					Msg("Failed to create tool execution job")
				if w.jobMgr != nil {
					w.jobMgr.AddJobLog(ctx, stepID, "error",
						fmt.Sprintf("Failed to create job for tool %s: %v", planStep.Tool, err))
				}
				completedSteps[planStep.ID] = true
				continue
			}

			waveJobIDs = append(waveJobIDs, toolJobID)
			toolJobMap[toolJobID] = planStep
			stepToJobID[planStep.ID] = toolJobID

			if w.jobMgr != nil {
				paramsJSON, _ := json.Marshal(planStep.Params)
				w.jobMgr.AddJobLog(ctx, stepID, "info",
					fmt.Sprintf("Created tool job: %s (tool: %s, worker: %s) params: %s",
						toolJobID, planStep.Tool, workerType, string(paramsJSON)))
			}

			w.logger.Info().
				Str("job_id", toolJobID).
				Str("tool", planStep.Tool).
				Str("worker_type", workerType).
				Str("plan_step_id", planStep.ID).
				Int("wave", wave+1).
				Msg("Created tool execution job")
		}

		// Wait for this wave to complete before starting next wave
		if len(waveJobIDs) > 0 {
			waveResults, err := w.waitForToolJobs(ctx, stepID, waveJobIDs, toolJobMap)
			if err != nil {
				w.logger.Error().Err(err).Int("wave", wave+1).Msg("Error waiting for wave tool jobs")
			}

			// Mark steps as completed and collect results
			for _, result := range waveResults {
				completedSteps[result.StepID] = true
				allResults = append(allResults, result)
			}

			if w.jobMgr != nil {
				successCount := 0
				for _, r := range waveResults {
					if r.Success {
						successCount++
					}
				}
				w.jobMgr.AddJobLog(ctx, stepID, "info",
					fmt.Sprintf("Wave %d complete: %d/%d tools succeeded", wave+1, successCount, len(waveResults)))
			}
		}
	}

	// Check if all steps were executed
	pendingSteps := 0
	for _, ps := range plan.Steps {
		if !completedSteps[ps.ID] {
			pendingSteps++
			w.logger.Warn().
				Str("step_id", ps.ID).
				Str("tool", ps.Tool).
				Strs("depends_on", ps.DependsOn).
				Msg("Step could not be executed (dependency cycle or missing dependency)")
		}
	}

	if len(allResults) == 0 {
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "error", "No tool jobs were created - execution cannot proceed")
		}
		return "", fmt.Errorf("no tool jobs created: all tools failed validation")
	}

	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("All waves complete: %d steps executed, %d pending", len(allResults), pendingSteps))
	}

	// Use allResults instead of results from here on
	results := allResults

	if w.jobMgr != nil {
		successCount := 0
		for _, r := range results {
			if r.Success {
				successCount++
			}
		}
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("Tool execution complete: %d/%d succeeded", successCount, len(results)))
	}

	// =========================================================================
	// PHASE 3: REVIEWER - Assess results and determine if goal was achieved
	// =========================================================================
	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Phase 3: REVIEWER - Assessing results...")
	}

	review, err := w.reviewResults(ctx, goal, results, thinkingLevel)
	if err != nil {
		w.logger.Warn().Err(err).Msg("Review phase failed, continuing anyway")
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "warning",
				fmt.Sprintf("Review failed: %v", err))
		}
	} else {
		if w.jobMgr != nil {
			status := "OK"
			if !review.GoalAchieved {
				status = "INCOMPLETE"
			}
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("[%s] Review complete: Goal achieved=%v, Confidence=%.0f%%",
					status, review.GoalAchieved, review.Confidence*100))
			w.jobMgr.AddJobLog(ctx, stepID, "info",
				fmt.Sprintf("Summary: %s", review.Summary))

			if len(review.MissingData) > 0 {
				w.jobMgr.AddJobLog(ctx, stepID, "warning",
					fmt.Sprintf("Missing data: %s", strings.Join(review.MissingData, ", ")))
			}

			if len(review.RecoveryActions) > 0 {
				w.jobMgr.AddJobLog(ctx, stepID, "info",
					fmt.Sprintf("Recovery actions suggested: %d", len(review.RecoveryActions)))
				// TODO: Implement recovery loop - re-run with suggested actions
			}
		}
	}

	// =========================================================================
	// SAVE OUTPUT DOCUMENT
	// =========================================================================
	// Build output content from plan and review results
	outputContent := w.buildOutputContent(goal, plan, results, review)

	// Save output document with tags from step config
	if err := w.saveOutputDocument(ctx, stepID, step, jobDef, outputContent); err != nil {
		w.logger.Warn().Err(err).Msg("Failed to save orchestrator output document")
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "warning", fmt.Sprintf("Failed to save output document: %v", err))
		}
	} else {
		if w.jobMgr != nil {
			w.jobMgr.AddJobLog(ctx, stepID, "info", "Output document saved")
		}
	}

	// =========================================================================
	// COMPLETE
	// =========================================================================
	goalAchieved := review != nil && review.GoalAchieved
	w.logger.Info().
		Str("phase", "complete").
		Str("step_name", step.Name).
		Str("step_id", stepID).
		Bool("goal_achieved", goalAchieved).
		Msg("Orchestration complete")

	if w.jobMgr != nil {
		w.jobMgr.AddJobLog(ctx, stepID, "info", "Orchestration complete")
	}

	// If goal was not achieved, return an error to mark step as failed
	// This prevents dependent steps from running when on_error = "fail"
	if !goalAchieved {
		summary := "Goal not achieved"
		if review != nil && review.Summary != "" {
			summary = review.Summary
		}
		return stepID, fmt.Errorf("orchestration goal not achieved: %s", summary)
	}

	return stepID, nil
}

// ReturnsChildJobs returns true since orchestrator creates tool execution jobs as queue citizens.
// Each tool call becomes a separate job visible in the queue with independent status tracking.
func (w *OrchestratorWorker) ReturnsChildJobs() bool {
	return true
}

// truncateString truncates a string to maxLen characters, adding "..." if truncated
func truncateString(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	if maxLen <= 3 {
		return s[:maxLen]
	}
	return s[:maxLen-3] + "..."
}

// extractTickers extracts ticker strings from variables array (from job config [config].variables)
// Returns uppercase ticker values for consistency in validation
func extractTickers(variables []map[string]interface{}) []string {
	var tickers []string
	for _, v := range variables {
		if ticker, ok := v["ticker"].(string); ok && ticker != "" {
			tickers = append(tickers, strings.ToUpper(ticker))
		}
	}
	return tickers
}

// extractBenchmarkCodes extracts benchmark code strings from benchmarks array (from job config [config].benchmarks)
// Returns uppercase codes for consistency in validation
func extractBenchmarkCodes(benchmarks []map[string]interface{}) []string {
	var codes []string
	for _, b := range benchmarks {
		if code, ok := b["code"].(string); ok && code != "" {
			codes = append(codes, strings.ToUpper(code))
		}
	}
	return codes
}

// formatVariablesAsContext formats variables and benchmarks from the job definition config
// as a context string for the LLM planner. This follows the standard job-definition pattern
// where user data is declared in [config] variables.
//
// IMPORTANT: Uses explicit labels to help the LLM distinguish between:
// - Variables = PRIMARY analysis targets (stocks to fetch and analyze with all tools)
// - Benchmarks = SECONDARY reference data (indices for comparison only)
func (w *OrchestratorWorker) formatVariablesAsContext(variables []map[string]interface{}, benchmarks []map[string]interface{}) string {
	if len(variables) == 0 && len(benchmarks) == 0 {
		return ""
	}

	var sb strings.Builder

	// Format variables (stocks, holdings, etc.) with explicit PRIMARY TARGET labeling
	if len(variables) > 0 {
		sb.WriteString("=== STOCKS TO ANALYZE (PRIMARY TARGETS) ===\n")
		sb.WriteString("These are the ASX stocks you MUST analyze. Call fetch_stock_data, fetch_announcements, and search_web for EACH ticker.\n\n")
		jsonBytes, err := json.MarshalIndent(map[string]interface{}{"stocks": variables}, "", "  ")
		if err == nil {
			sb.WriteString(string(jsonBytes))
		} else {
			// Fallback to simple format
			for i, v := range variables {
				sb.WriteString(fmt.Sprintf("%d. %v\n", i+1, v))
			}
		}
	}

	// Format benchmarks with explicit SECONDARY/COMPARISON labeling
	if len(benchmarks) > 0 {
		if sb.Len() > 0 {
			sb.WriteString("\n\n")
		}
		sb.WriteString("=== BENCHMARK INDICES (for comparison only) ===\n")
		sb.WriteString("These are market indices for comparison. Call fetch_index_data for these codes.\n\n")
		jsonBytes, err := json.MarshalIndent(map[string]interface{}{"indices": benchmarks}, "", "  ")
		if err == nil {
			sb.WriteString(string(jsonBytes))
		} else {
			for i, b := range benchmarks {
				sb.WriteString(fmt.Sprintf("%d. %v\n", i+1, b))
			}
		}
	}

	return sb.String()
}

// formatToolsForPrompt formats available tools as a string for the LLM prompt
func (w *OrchestratorWorker) formatToolsForPrompt(tools []map[string]interface{}) string {
	if len(tools) == 0 {
		return "No tools available."
	}

	var sb strings.Builder
	sb.WriteString("Available Tools:\n")

	for i, tool := range tools {
		name, _ := tool["name"].(string)
		desc, _ := tool["description"].(string)
		worker, _ := tool["worker"].(string)

		sb.WriteString(fmt.Sprintf("%d. %s", i+1, name))
		if worker != "" {
			sb.WriteString(fmt.Sprintf(" (worker: %s)", worker))
		}
		if desc != "" {
			sb.WriteString(fmt.Sprintf("\n   Description: %s", desc))
		}
		sb.WriteString("\n")
	}

	return sb.String()
}

// generatePlan uses LLM to create an execution plan based on goal and context
func (w *OrchestratorWorker) generatePlan(ctx context.Context, goal string, contextContent string, tools []map[string]interface{}, thinkingLevel string, modelPreference string, stepID string) (*Plan, error) {
	// Build the user prompt
	var userPrompt strings.Builder
	userPrompt.WriteString("GOAL:\n")
	userPrompt.WriteString(goal)
	userPrompt.WriteString("\n\n")

	if contextContent != "" {
		userPrompt.WriteString("CONTEXT:\n")
		userPrompt.WriteString(contextContent)
		userPrompt.WriteString("\n\n")
	}

	userPrompt.WriteString(w.formatToolsForPrompt(tools))
	userPrompt.WriteString("\n\nCreate an execution plan to achieve the goal. Output ONLY valid JSON.")

	// Determine model based on preference
	// Supports both Gemini and Claude model selections
	var model string
	switch strings.ToLower(modelPreference) {
	// Gemini models
	case "flash", "gemini-flash":
		model = "gemini-3-flash-preview"
	case "pro", "gemini-pro":
		model = "gemini-3-pro-preview"
	// Claude models
	case "claude", "claude-sonnet", "sonnet":
		model = "claude-sonnet-4-5-20250929"
	case "claude-opus", "opus":
		model = "claude-opus-4-5-20251101"
	case "claude-haiku", "haiku":
		model = "claude-haiku-4-5-20251001"
	default:
		model = "" // Use provider default
	}

	// Log the model selection for visibility (server logs only - UI log after call)
	if model != "" {
		w.logger.Info().
			Str("model_preference", modelPreference).
			Str("model", model).
			Msg("LLM model selected for orchestrator planning")
	} else {
		w.logger.Info().
			Str("model_preference", modelPreference).
			Msg("Using default LLM model from provider configuration")
	}

	// Call LLM
	request := &llm.ContentRequest{
		Messages: []interfaces.Message{
			{Role: "user", Content: userPrompt.String()},
		},
		Model:             model,
		SystemInstruction: plannerSystemPrompt,
		ThinkingLevel:     thinkingLevel,
	}

	response, err := w.providerFactory.GenerateContent(ctx, request)
	if err != nil {
		return nil, fmt.Errorf("LLM planning failed: %w", err)
	}

	// Log actual model used to UI (now we know from response)
	if w.jobMgr != nil && stepID != "" {
		actualModel := response.Model
		if actualModel == "" {
			actualModel = "unknown"
		}
		w.jobMgr.AddJobLog(ctx, stepID, "info",
			fmt.Sprintf("LLM Model: %s (preference: %s)", actualModel, modelPreference))
	}

	// Parse JSON response
	responseText := strings.TrimSpace(response.Text)

	// Remove markdown code blocks if present
	responseText = strings.TrimPrefix(responseText, "```json")
	responseText = strings.TrimPrefix(responseText, "```")
	responseText = strings.TrimSuffix(responseText, "```")
	responseText = strings.TrimSpace(responseText)

	var plan Plan
	if err := json.Unmarshal([]byte(responseText), &plan); err != nil {
		w.logger.Error().
			Str("response", truncateString(responseText, 500)).
			Err(err).
			Msg("Failed to parse LLM plan response")
		return nil, fmt.Errorf("failed to parse plan JSON: %w", err)
	}

	// Check if planner returned an error (could not create valid plan)
	if plan.Error {
		w.logger.Warn().
			Str("reasoning", plan.Reasoning).
			Msg("Planner returned error - cannot achieve goal with available tools")
		return nil, fmt.Errorf("planning failed: %s", plan.Reasoning)
	}

	// FORCED TOOL USE: Require at least one tool call
	if len(plan.Steps) == 0 {
		w.logger.Error().
			Str("reasoning", plan.Reasoning).
			Msg("Planning failed: no tool calls returned (forced tool use violation)")
		return nil, fmt.Errorf("planning failed: no tool calls returned - AI must call at least one tool")
	}

	// Validate plan steps for common mistakes (e.g., mutually exclusive filter_tags)
	if err := validatePlanSteps(&plan); err != nil {
		w.logger.Error().
			Err(err).
			Str("reasoning", plan.Reasoning).
			Msg("Plan validation failed: invalid filter_tags combination detected")
		return nil, fmt.Errorf("plan validation failed: %w", err)
	}

	w.logger.Info().
		Str("reasoning", plan.Reasoning).
		Int("steps", len(plan.Steps)).
		Msg("Generated execution plan")

	return &plan, nil
}

// ReviewResult represents the reviewer's assessment
type ReviewResult struct {
	GoalAchieved    bool                     `json:"goal_achieved"`
	Confidence      float64                  `json:"confidence"`
	Summary         string                   `json:"summary"`
	MissingData     []string                 `json:"missing_data"`
	RecoveryActions []map[string]interface{} `json:"recovery_actions"`
}

// reviewResults uses LLM to assess if the goal was achieved
func (w *OrchestratorWorker) reviewResults(ctx context.Context, goal string, results []PlanStepResult, thinkingLevel string) (*ReviewResult, error) {
	// Format results for review
	var resultsText strings.Builder
	resultsText.WriteString("EXECUTION RESULTS:\n\n")

	for _, r := range results {
		resultsText.WriteString(fmt.Sprintf("Step: %s (tool: %s)\n", r.StepID, r.Tool))
		if r.Success {
			resultsText.WriteString(fmt.Sprintf("Status: SUCCESS\nOutput: %s\n\n", truncateString(r.Output, 1000)))
		} else {
			resultsText.WriteString(fmt.Sprintf("Status: FAILED\nError: %s\n\n", r.Error))
		}
	}

	// Build review prompt
	userPrompt := fmt.Sprintf("ORIGINAL GOAL:\n%s\n\n%s\n\nReview these results and determine if the goal was achieved. Output ONLY valid JSON.",
		goal, resultsText.String())

	request := &llm.ContentRequest{
		Messages: []interfaces.Message{
			{Role: "user", Content: userPrompt},
		},
		SystemInstruction: reviewerSystemPrompt,
		ThinkingLevel:     thinkingLevel,
	}

	response, err := w.providerFactory.GenerateContent(ctx, request)
	if err != nil {
		return nil, fmt.Errorf("LLM review failed: %w", err)
	}

	// Parse JSON response
	responseText := strings.TrimSpace(response.Text)
	responseText = strings.TrimPrefix(responseText, "```json")
	responseText = strings.TrimPrefix(responseText, "```")
	responseText = strings.TrimSuffix(responseText, "```")
	responseText = strings.TrimSpace(responseText)

	var review ReviewResult
	if err := json.Unmarshal([]byte(responseText), &review); err != nil {
		w.logger.Warn().
			Str("response", truncateString(responseText, 500)).
			Err(err).
			Msg("Failed to parse review response, assuming goal not achieved")
		return &ReviewResult{
			GoalAchieved: false,
			Confidence:   0.5,
			Summary:      "Review parsing failed",
		}, nil
	}

	return &review, nil
}

// executeTool executes a single tool via StepManager and returns the result.
// It resolves the tool configuration from available_tools and creates a synthetic JobStep.
func (w *OrchestratorWorker) executeTool(
	ctx context.Context,
	planStep PlanStep,
	toolConfig map[string]interface{},
	jobDef models.JobDefinition,
	parentJobID string,
) PlanStepResult {
	result := PlanStepResult{
		StepID:  planStep.ID,
		Tool:    planStep.Tool,
		Success: false,
	}

	// Get worker type from tool config
	workerType, ok := toolConfig["worker"].(string)
	if !ok || workerType == "" {
		result.Error = fmt.Sprintf("tool '%s' has no worker type configured", planStep.Tool)
		return result
	}

	// Build step config from tool config and plan step params
	stepConfig := make(map[string]interface{})

	// Copy tool-specific config (like 'template' for job_template worker)
	for k, v := range toolConfig {
		if k != "name" && k != "description" && k != "worker" {
			stepConfig[k] = v
		}
	}

	// Merge plan step params (these override tool config)
	for k, v := range planStep.Params {
		stepConfig[k] = v
	}

	// Create synthetic JobStep
	syntheticStep := models.JobStep{
		Name:        fmt.Sprintf("orchestrated_%s", planStep.ID),
		Type:        models.WorkerType(workerType),
		Description: fmt.Sprintf("Orchestrated execution of %s", planStep.Tool),
		Config:      stepConfig,
		OnError:     models.ErrorStrategyContinue,
	}

	w.logger.Debug().
		Str("step_id", planStep.ID).
		Str("tool", planStep.Tool).
		Str("worker_type", workerType).
		Msg("Executing tool via StepManager")

	// Execute via StepManager
	_, err := w.stepManager.Execute(ctx, syntheticStep, jobDef, parentJobID, nil)
	if err != nil {
		result.Error = fmt.Sprintf("tool execution failed: %v", err)
		w.logger.Warn().
			Err(err).
			Str("step_id", planStep.ID).
			Str("tool", planStep.Tool).
			Msg("Tool execution failed")
		return result
	}

	result.Success = true
	result.Output = fmt.Sprintf("Successfully executed %s (worker: %s)", planStep.Tool, workerType)

	// Try to find and summarize output documents created by this tool
	// Workers typically tag their output with job-specific tags
	if w.searchService != nil {
		// Search for recent documents with tags matching the step name
		searchOpts := interfaces.SearchOptions{
			Limit: 5,
			// Note: We don't filter by tags here because we don't know what tags the worker used.
			// The worker output is already captured by the parent job's document storage.
		}

		// Search for documents created in the last few minutes with content from this execution
		docs, err := w.searchService.Search(ctx, syntheticStep.Name, searchOpts)
		if err == nil && len(docs) > 0 {
			var docSummaries []string
			for _, doc := range docs {
				summary := truncateString(doc.ContentMarkdown, 500)
				docSummaries = append(docSummaries, fmt.Sprintf("- %s: %s", doc.Title, summary))
			}
			if len(docSummaries) > 0 {
				result.Output = fmt.Sprintf("Executed %s (worker: %s). Output documents:\n%s",
					planStep.Tool, workerType, strings.Join(docSummaries, "\n"))
			}
		}
	}

	w.logger.Info().
		Str("step_id", planStep.ID).
		Str("tool", planStep.Tool).
		Bool("success", result.Success).
		Msg("Tool execution completed")

	return result
}

// waitForToolJobs polls for completion of tool execution jobs and collects results.
// This enables asynchronous tool execution while maintaining the orchestration flow.
func (w *OrchestratorWorker) waitForToolJobs(ctx context.Context, parentStepID string, toolJobIDs []string, toolJobMap map[string]PlanStep) ([]PlanStepResult, error) {
	const (
		pollInterval = 2 * time.Second
		maxWaitTime  = 10 * time.Minute
	)

	startTime := time.Now()
	results := make([]PlanStepResult, 0, len(toolJobIDs))
	completedJobs := make(map[string]bool)

	w.logger.Info().
		Int("job_count", len(toolJobIDs)).
		Str("parent_step_id", parentStepID).
		Msg("Starting tool job polling")

	for {
		// Check for context cancellation
		select {
		case <-ctx.Done():
			return results, ctx.Err()
		default:
		}

		// Check if max wait time exceeded
		if time.Since(startTime) > maxWaitTime {
			w.logger.Warn().
				Dur("elapsed", time.Since(startTime)).
				Int("completed", len(completedJobs)).
				Int("total", len(toolJobIDs)).
				Msg("Tool job polling timed out")
			return results, fmt.Errorf("tool job polling timed out after %v", maxWaitTime)
		}

		// Check status of each job
		allComplete := true
		for _, jobID := range toolJobIDs {
			if completedJobs[jobID] {
				continue
			}

			// Get job status
			jobInterface, err := w.jobMgr.GetJob(ctx, jobID)
			if err != nil {
				w.logger.Warn().Err(err).Str("job_id", jobID).Msg("Failed to get tool job status")
				continue
			}

			jobState, ok := jobInterface.(*models.QueueJobState)
			if !ok {
				continue
			}

			// Check if job is in terminal state
			isTerminal := jobState.Status == models.JobStatusCompleted ||
				jobState.Status == models.JobStatusFailed ||
				jobState.Status == models.JobStatusCancelled

			if isTerminal {
				completedJobs[jobID] = true
				planStep := toolJobMap[jobID]

				result := PlanStepResult{
					StepID: planStep.ID,
					Tool:   planStep.Tool,
				}

				if jobState.Status == models.JobStatusCompleted {
					result.Success = true
					// Try to get output from job metadata or search for documents
					if output, ok := jobState.Metadata["output"].(string); ok {
						result.Output = output
					} else {
						result.Output = fmt.Sprintf("Tool %s completed successfully", planStep.Tool)
					}
				} else {
					result.Success = false
					result.Error = jobState.Error
					if result.Error == "" {
						result.Error = fmt.Sprintf("Tool %s failed with status: %s", planStep.Tool, jobState.Status)
					}
				}

				results = append(results, result)

				w.logger.Debug().
					Str("job_id", jobID).
					Str("tool", planStep.Tool).
					Str("status", string(jobState.Status)).
					Bool("success", result.Success).
					Msg("Tool job completed")

				if w.jobMgr != nil {
					if result.Success {
						w.jobMgr.AddJobLog(ctx, parentStepID, "debug",
							fmt.Sprintf("Tool job %s completed: %s", planStep.Tool, truncateString(result.Output, 100)))
					} else {
						w.jobMgr.AddJobLog(ctx, parentStepID, "warning",
							fmt.Sprintf("Tool job %s failed: %s", planStep.Tool, result.Error))
					}
				}
			} else {
				allComplete = false
			}
		}

		if allComplete && len(completedJobs) == len(toolJobIDs) {
			w.logger.Info().
				Int("completed", len(completedJobs)).
				Dur("elapsed", time.Since(startTime)).
				Msg("All tool jobs completed")
			break
		}

		// Wait before next poll
		time.Sleep(pollInterval)
	}

	return results, nil
}

// buildOutputContent creates markdown content from orchestration results
func (w *OrchestratorWorker) buildOutputContent(goal string, plan *Plan, results []PlanStepResult, review *ReviewResult) string {
	var sb strings.Builder

	sb.WriteString("# Orchestration Results\n\n")

	// Goal section
	sb.WriteString("## Goal\n")
	sb.WriteString(goal)
	sb.WriteString("\n\n")

	// Plan summary
	if plan != nil {
		sb.WriteString("## Execution Plan\n")
		sb.WriteString(fmt.Sprintf("**Reasoning:** %s\n\n", plan.Reasoning))

		if len(plan.Steps) > 0 {
			sb.WriteString("### Steps\n")
			for i, step := range plan.Steps {
				sb.WriteString(fmt.Sprintf("%d. **%s** (tool: %s)\n", i+1, step.ID, step.Tool))
			}
			sb.WriteString("\n")
		}
	}

	// Execution results
	if len(results) > 0 {
		sb.WriteString("## Execution Results\n\n")
		for _, result := range results {
			status := "Success"
			if !result.Success {
				status = "Failed"
			}
			sb.WriteString(fmt.Sprintf("### %s (%s)\n", result.StepID, status))
			if result.Success {
				sb.WriteString(result.Output)
			} else {
				sb.WriteString(fmt.Sprintf("Error: %s", result.Error))
			}
			sb.WriteString("\n\n")
		}
	}

	// Review summary
	if review != nil {
		sb.WriteString("## Review Summary\n\n")
		goalStatus := "Not Achieved"
		if review.GoalAchieved {
			goalStatus = "Achieved"
		}
		sb.WriteString(fmt.Sprintf("- **Goal Status:** %s\n", goalStatus))
		sb.WriteString(fmt.Sprintf("- **Confidence:** %.0f%%\n", review.Confidence*100))
		sb.WriteString(fmt.Sprintf("- **Summary:** %s\n", review.Summary))

		if len(review.MissingData) > 0 {
			sb.WriteString(fmt.Sprintf("- **Missing Data:** %s\n", strings.Join(review.MissingData, ", ")))
		}
	}

	return sb.String()
}

// saveOutputDocument saves the orchestration execution log as a document.
// IMPORTANT: This document uses INTERNAL tags only (orchestrator-execution-log),
// NOT the output_tags from step config. This ensures that worker-produced
// documents (which have the actual content) are found by downstream steps
// like email, instead of this execution summary.
func (w *OrchestratorWorker) saveOutputDocument(ctx context.Context, stepID string, step models.JobStep, jobDef models.JobDefinition, content string) error {
	if content == "" {
		return nil // Nothing to save
	}

	now := time.Now()

	// Use INTERNAL tags only - NOT output_tags from step config
	// This prevents the orchestrator's execution summary from overshadowing
	// the actual content produced by workers (which use output_tags)
	tags := []string{"orchestrator-execution-log"}

	// Add job tags
	if len(jobDef.Tags) > 0 {
		tags = append(tags, jobDef.Tags...)
	}

	// Create title from step description or job name
	title := step.Description
	if title == "" {
		title = jobDef.Name
	}
	if title == "" {
		title = "Orchestration Output"
	}

	doc := &models.Document{
		ID:              "doc_" + uuid.New().String(),
		SourceType:      "orchestrator",
		SourceID:        stepID,
		Title:           title,
		ContentMarkdown: content,
		DetailLevel:     models.DetailLevelFull,
		Metadata: map[string]interface{}{
			"job_id":  jobDef.ID,
			"step_id": stepID,
		},
		Tags:       tags,
		CreatedAt:  now,
		UpdatedAt:  now,
		LastSynced: &now,
	}

	if err := w.documentStorage.SaveDocument(doc); err != nil {
		return fmt.Errorf("failed to save document: %w", err)
	}

	w.logger.Info().
		Str("doc_id", doc.ID).
		Strs("tags", tags).
		Int("content_len", len(content)).
		Msg("Saved orchestrator output document")

	return nil
}
